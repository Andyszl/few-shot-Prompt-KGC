{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据加载\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 8707 条三元组\n",
      "验证集大小: 1187 条三元组\n"
     ]
    }
   ],
   "source": [
    "# 加载 FB15k-237 数据集的训练、验证和测试集\n",
    "data_dir = \"./knowledge_graph_completion/data/OpenBG500/\"\n",
    "train_df, valid_df = pd.read_csv(data_dir+\"train.csv\"),pd.read_csv(data_dir+\"test.csv\")\n",
    "print(f\"训练集大小: {len(train_df)} 条三元组\")\n",
    "print(f\"验证集大小: {len(valid_df)} 条三元组\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>婴儿围嘴</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>16*10CM*2个</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>如担心下围短，可联系客服送排扣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>卫衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>均</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>卫衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>不加绒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>诺瓦纳内衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>S下胸围65-80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               head relation             tail\n",
       "0                              婴儿围嘴     文胸尺码       16*10CM*2个\n",
       "1  大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季     文胸尺码  如担心下围短，可联系客服送排扣\n",
       "2                                卫衣     文胸尺码                均\n",
       "3                                卫衣     文胸尺码              不加绒\n",
       "4                             诺瓦纳内衣     文胸尺码        S下胸围65-80"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['head','relation','tail']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数便于打印三元组列表的前几项\n",
    "def preview_triples(name, df, num=5):\n",
    "    print(f\"\\n{name} 集合样本前 {num} 条：\")\n",
    "    for _, row in df.head(num).iterrows():\n",
    "        print(f\"{row['head']}\\t{row['relation']}\\t{row['tail']}\")\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "训练 集合样本前 5 条：\n",
      "婴儿围嘴\t文胸尺码\t16*10CM*2个\n",
      "大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季\t文胸尺码\t如担心下围短，可联系客服送排扣\n",
      "卫衣\t文胸尺码\t均\n",
      "卫衣\t文胸尺码\t不加绒\n",
      "诺瓦纳内衣\t文胸尺码\tS下胸围65-80\n",
      "...\n",
      "\n",
      "验证 集合样本前 5 条：\n",
      "文胸\t文胸尺码\t常规\n",
      "超薄运动内衣大胸健身减震跑步大码运动文胸200斤防震女胖mm夏季\t文胸尺码\t本款文胸偏大，建议咨询客服\n",
      "卫衣\t文胸尺码\t不加绒\n",
      "少女文胸\t文胸尺码\t均码\n",
      "文胸\t文胸尺码\t常规\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "preview_triples(\"训练\", train_df, num=5)\n",
    "preview_triples(\"验证\", valid_df, num=5)\n",
    "# preview_triples(\"测试\", test_df, num=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建 Few-Shot 提示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = list(train_df[['head','relation','tail']].itertuples(index=False, name=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从训练集中选择关系为 \"founded\" 的 few-shot 示例\n",
    "relation = \"文胸尺码\"\n",
    "K = 3  # 选取3条few-shot示例\n",
    "fewshot_examples = [trip for trip in triples if trip[1] == relation][:K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('婴儿围嘴', '文胸尺码', '16*10CM*2个'),\n",
       " ('大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季', '文胸尺码', '如担心下围短，可联系客服送排扣'),\n",
       " ('卫衣', '文胸尺码', '均')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fewshot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "构建的提示 Prompt:\n",
      "婴儿围嘴 - 文胸尺码 -> 16*10CM*2个\n",
      "大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季 - 文胸尺码 -> 如担心下围短，可联系客服送排扣\n",
      "卫衣 - 文胸尺码 -> 均\n",
      "卫衣 - 文胸尺码 ->\n"
     ]
    }
   ],
   "source": [
    "query_head = \"卫衣\"\n",
    "query_relation = \"文胸尺码\"\n",
    "prompt = \"\"\n",
    "for h, r, t in fewshot_examples:\n",
    "    prompt += f\"{h} - {r} -> {t}\\n\"\n",
    "prompt += f\"{query_head} - {query_relation} ->\"\n",
    "\n",
    "print(\"\\n构建的提示 Prompt:\\n\" + prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型推理生成尾实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 Qwen3-0.6B 模型和分词器\n",
    "model_name = \"./knowledge_graph_completion/models/Qwen3-0.6B/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)                      # 把模型权重移动到 GPU\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将提示编码为模型输入并生成文本\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(device)            # GPU Tensor\n",
    "attention_mask = inputs.attention_mask.to(device)  # 如果有"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:631: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:636: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:653: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=10,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    只取 prompt 后生成部分\n",
    "generated_ids = outputs[0, input_ids.shape[1]:].cpu()\n",
    "raw = tokenizer.decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测尾实体： 16*10CM*2个\n"
     ]
    }
   ],
   "source": [
    "# 只保留第一行（遇到换行就截断）\n",
    "pred = raw.splitlines()[0].strip()\n",
    "print(\"预测尾实体：\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hits@1 和 MRR 指标评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 评估前 N 条测试集样本\n",
    "N = min(2000, len(valid_df))\n",
    "hits1_count = 0\n",
    "ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [14:26<00:00,  1.37it/s] \n"
     ]
    }
   ],
   "source": [
    "for i, (_, row) in enumerate(tqdm(valid_df.head(N).iterrows(), total=N, desc=\"Evaluating\")):\n",
    "    \n",
    "    # 直接从 row 里取列：\n",
    "    h = row['head']      # 或者 row['head']，如果想用 MID\n",
    "    r = row['relation']       # 原始谓词标识\n",
    "    true_t = row['tail'] # 或者 row['tail']\n",
    "    \n",
    "    # 构建 Few-Shot 提示\n",
    "    fs = train_df[train_df['relation'] == r].head(3)\n",
    "    prompt_i = \"\"\n",
    "    for _, ex in fs.iterrows():\n",
    "        prompt_i += f\"{ex['head']} - {ex['relation']} -> {ex['tail']}\\n\"\n",
    "    prompt_i += f\"{h} - {r} ->\"\n",
    "    \n",
    "    # 模型生成预测\n",
    "    inputs_i = tokenizer(prompt_i, return_tensors=\"pt\")\n",
    "    input_ids = inputs_i.input_ids.to(device)            # GPU Tensor\n",
    "    attention_mask = inputs_i.attention_mask.to(device)  # 如果有\n",
    "    outputs = model.generate(input_ids=input_ids,attention_mask=attention_mask,max_new_tokens=10,do_sample=False)\n",
    "    generated_ids = outputs[0, input_ids.shape[1]:].cpu()\n",
    "    pred = tokenizer.decode(generated_ids, skip_special_tokens=True).splitlines()[0].strip()\n",
    "\n",
    "    # 统计 Hits@1 与 MRR\n",
    "    hit = int(pred == true_t)\n",
    "    hits1_count += hit\n",
    "    ranks.append(1.0 if hit else 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1 = 0.4170, MRR = 0.4170\n"
     ]
    }
   ],
   "source": [
    "hits1 = hits1_count / N\n",
    "mrr   = sum(ranks) / N\n",
    "print(f\"Hits@1 = {hits1:.4f}, MRR = {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 实际测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_graph_completion.infer import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [06:07<00:00,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.0219, Hits@3: 0.0514, Hits@10: 0.0708, MRR: 0.0396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=0)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [06:31<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.3555, Hits@3: 0.4078, Hits@10: 0.4414, MRR: 0.3855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#N = min(100, len(valid_df))\n",
    "\n",
    "hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=1)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [07:37<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4204, Hits@3: 0.5063, Hits@10: 0.5569, MRR: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=3)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [12:36<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4642, Hits@3: 0.5619, Hits@10: 0.6192, MRR: 0.5194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=5)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 fewshot不同数量对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "num_examples= 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [17:46<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4836, Hits@3: 0.5737, Hits@10: 0.6361, MRR: 0.5357\n",
      "****************************************************************************************************\n",
      "num_examples= 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [16:41<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5131, Hits@3: 0.5998, Hits@10: 0.6757, MRR: 0.5664\n",
      "****************************************************************************************************\n",
      "num_examples= 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [23:01<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5055, Hits@3: 0.6226, Hits@10: 0.6900, MRR: 0.5715\n",
      "****************************************************************************************************\n",
      "num_examples= 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [19:11<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5324, Hits@3: 0.6487, Hits@10: 0.7094, MRR: 0.5960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,15,2):\n",
    "    print(\"*\"*100)\n",
    "    print(\"num_examples=\",i)\n",
    "    hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=i)\n",
    "    print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "num_examples= 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [07:04<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.3934, Hits@3: 0.4541, Hits@10: 0.5046, MRR: 0.4287\n",
      "****************************************************************************************************\n",
      "num_examples= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [08:10<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4524, Hits@3: 0.5383, Hits@10: 0.5855, MRR: 0.5005\n",
      "****************************************************************************************************\n",
      "num_examples= 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [09:10<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4743, Hits@3: 0.5762, Hits@10: 0.6361, MRR: 0.5297\n",
      "****************************************************************************************************\n",
      "num_examples= 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [10:20<00:00,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5013, Hits@3: 0.6032, Hits@10: 0.6630, MRR: 0.5585\n",
      "****************************************************************************************************\n",
      "num_examples= 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [11:29<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5173, Hits@3: 0.6268, Hits@10: 0.6799, MRR: 0.5752\n",
      "****************************************************************************************************\n",
      "num_examples= 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [12:41<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5257, Hits@3: 0.6293, Hits@10: 0.7009, MRR: 0.5853\n",
      "****************************************************************************************************\n",
      "num_examples= 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [13:51<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.5307, Hits@3: 0.6268, Hits@10: 0.6891, MRR: 0.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,15,2):\n",
    "    print(\"*\"*100)\n",
    "    print(\"num_examples=\",i)\n",
    "    hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, num_examples=i)\n",
    "    print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1 = 0.3110, MRR = 0.3441\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hits@1 = {hits1:.4f}, MRR = {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LoRA训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from knowledge_graph_completion.infer import evaluate_model\n",
    "from knowledge_graph_completion.utils import calculate_metrics\n",
    "from knowledge_graph_completion.data.data_loader import load_openbg500\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据（已含 head_name, tail_name, relation_name）\n",
    "import pandas as pd\n",
    "data_dir = \"./knowledge_graph_completion/data/OpenBG500/\"\n",
    "train_df, valid_df = pd.read_csv(data_dir+\"train.csv\"),pd.read_csv(data_dir+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>婴儿围嘴</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>16*10CM*2个</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>如担心下围短，可联系客服送排扣</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>卫衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>均</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>卫衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>不加绒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>诺瓦纳内衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>S下胸围65-80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               head relation             tail\n",
       "0                              婴儿围嘴     文胸尺码       16*10CM*2个\n",
       "1  大码内衣女超薄款大胸显小神器缩胸防下垂文胸胖mm200斤胸罩夏季     文胸尺码  如担心下围短，可联系客服送排扣\n",
       "2                                卫衣     文胸尺码                均\n",
       "3                                卫衣     文胸尺码              不加绒\n",
       "4                             诺瓦纳内衣     文胸尺码        S下胸围65-80"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载分词器与模型\n",
    "model_name = \"./knowledge_graph_completion/models/Qwen3-0.6B/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_graph_completion.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 构建微调样本（随机挑 1000 条）\n",
    "sample_df_train = train_df.sample(n=1000, random_state=42).reset_index(drop=True)\n",
    "sample_df_test = valid_df.sample(n=1000, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>相伴一生办公桌垫 超大号可定制尺寸图案鼠标垫电脑书桌垫子男女笔记本键盘垫家用桌垫学生 写字桌...</td>\n",
       "      <td>单面双面</td>\n",
       "      <td>双面</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>紫砂杯</td>\n",
       "      <td>保温时长</td>\n",
       "      <td>6小时以下</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>有机大米</td>\n",
       "      <td>是否转基因</td>\n",
       "      <td>否</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>婴儿电热蚊香液</td>\n",
       "      <td>是否含香味</td>\n",
       "      <td>无香</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>俄罗斯巧克力</td>\n",
       "      <td>糖种类</td>\n",
       "      <td>喜糖</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>【下单立减450元】realme 真我GT 5G高通骁龙888处理器65W闪充游戏学生手机</td>\n",
       "      <td>CPU型号</td>\n",
       "      <td>骁龙888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>熟冻智利帝王蟹</td>\n",
       "      <td>保鲜工艺</td>\n",
       "      <td>熟冻</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>带鱼段</td>\n",
       "      <td>保鲜工艺</td>\n",
       "      <td>常温</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>婴儿床垫</td>\n",
       "      <td>床垫类型</td>\n",
       "      <td>乳胶床垫</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>双层不锈钢保温杯</td>\n",
       "      <td>保温时长</td>\n",
       "      <td>12小时(含)-24小时(不含)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  head relation  \\\n",
       "0    相伴一生办公桌垫 超大号可定制尺寸图案鼠标垫电脑书桌垫子男女笔记本键盘垫家用桌垫学生 写字桌...     单面双面   \n",
       "1                                                  紫砂杯     保温时长   \n",
       "2                                                 有机大米    是否转基因   \n",
       "3                                              婴儿电热蚊香液    是否含香味   \n",
       "4                                               俄罗斯巧克力      糖种类   \n",
       "..                                                 ...      ...   \n",
       "995      【下单立减450元】realme 真我GT 5G高通骁龙888处理器65W闪充游戏学生手机    CPU型号   \n",
       "996                                            熟冻智利帝王蟹     保鲜工艺   \n",
       "997                                                带鱼段     保鲜工艺   \n",
       "998                                               婴儿床垫     床垫类型   \n",
       "999                                           双层不锈钢保温杯     保温时长   \n",
       "\n",
       "                 tail  \n",
       "0                  双面  \n",
       "1               6小时以下  \n",
       "2                   否  \n",
       "3                  无香  \n",
       "4                  喜糖  \n",
       "..                ...  \n",
       "995             骁龙888  \n",
       "996                熟冻  \n",
       "997                常温  \n",
       "998              乳胶床垫  \n",
       "999  12小时(含)-24小时(不含)  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 63/63 [02:32<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] 平均 Loss: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1000/1000 [06:26<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.1790, Hits@3: 0.2380, Hits@10: 0.2760, MRR: 0.2127\n",
      "→ 保存最佳模型，MRR: 0.2127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 63/63 [02:43<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] 平均 Loss: 0.6850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1000/1000 [06:27<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.1660, Hits@3: 0.2100, Hits@10: 0.2670, MRR: 0.1955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 63/63 [02:43<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] 平均 Loss: 0.4245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1000/1000 [06:24<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.1830, Hits@3: 0.2500, Hits@10: 0.3050, MRR: 0.2233\n",
      "→ 保存最佳模型，MRR: 0.2233\n",
      "训练完成，最佳模型保存在: ./outputs/openBG500/best_model\n",
      "微调训练完毕，最佳模型已保存到 outputs/best_model/\n"
     ]
    }
   ],
   "source": [
    "# train_model 内部会将验证集上的最佳模型保存在 outputs/best_model/\n",
    "train_model(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_data=sample_df_train,      # DataFrame，含 head/relation/tail 和 head_name/... 列\n",
    "    valid_data=sample_df_test,      # DataFrame，用于早停 & 模型选择\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    learning_rate=5e-5,\n",
    "    output_dir=\"./outputs/openBG500/\",     # best_model 将保存在 outputs/best_model/\n",
    "    num_examples=3,\n",
    "    top_k=10\n",
    ")\n",
    "print(\"微调训练完毕，最佳模型已保存到 outputs/best_model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_dir      = \"/root/szl/KG/knowledge_graph_completion/outputs/checkpoint-3450\"\n",
    "base_model_name  = \"./knowledge_graph_completion/models/Qwen3-0.6B/\"\n",
    "\n",
    "# 1. 先加载基础模型和 tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3ForCausalLM(\n",
       "  (model): Qwen3Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen3DecoderLayer(\n",
       "        (self_attn): Qwen3Attention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "        )\n",
       "        (mlp): Qwen3MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "    (rotary_emb): Qwen3RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据（已含 head_name, tail_name, relation_name）\n",
    "import pandas as pd\n",
    "data_dir = \"./knowledge_graph_completion/data/OpenBG500/\"\n",
    "train_df, valid_df = pd.read_csv(data_dir+\"train.csv\"),pd.read_csv(data_dir+\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>relation</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>文胸</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>常规</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>超薄运动内衣大胸健身减震跑步大码运动文胸200斤防震女胖mm夏季</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>本款文胸偏大，建议咨询客服</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>卫衣</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>不加绒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>少女文胸</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>均码</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>文胸</td>\n",
       "      <td>文胸尺码</td>\n",
       "      <td>常规</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               head relation           tail\n",
       "0                                文胸     文胸尺码             常规\n",
       "1  超薄运动内衣大胸健身减震跑步大码运动文胸200斤防震女胖mm夏季     文胸尺码  本款文胸偏大，建议咨询客服\n",
       "2                                卫衣     文胸尺码            不加绒\n",
       "3                              少女文胸     文胸尺码             均码\n",
       "4                                文胸     文胸尺码             常规"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_graph_completion.infer import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [37:48<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4204, Hits@3: 0.5063, Hits@10: 0.5569, MRR: 0.4688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hits1, hits3, hits10, mrr = evaluate_model(model, tokenizer, valid_df, train_df, fewshot_k=3)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/kgc/lib/python3.11/site-packages/awq/__init__.py:21: DeprecationWarning: \n",
      "I have left this message as the final dev message to help you transition.\n",
      "\n",
      "Important Notice:\n",
      "- AutoAWQ is officially deprecated and will no longer be maintained.\n",
      "- The last tested configuration used Torch 2.6.0 and Transformers 4.51.3.\n",
      "- If future versions of Transformers break AutoAWQ compatibility, please report the issue to the Transformers project.\n",
      "\n",
      "Alternative:\n",
      "- AutoAWQ has been adopted by the vLLM Project: https://github.com/vllm-project/llm-compressor\n",
      "\n",
      "For further inquiries, feel free to reach out:\n",
      "- X: https://x.com/casper_hansen_\n",
      "- LinkedIn: https://www.linkedin.com/in/casper-hansen-804005170/\n",
      "\n",
      "  warnings.warn(_FINAL_DEV_MESSAGE, category=DeprecationWarning, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Qwen3ForCausalLM(\n",
       "      (model): Qwen3Model(\n",
       "        (embed_tokens): Embedding(151936, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x Qwen3DecoderLayer(\n",
       "            (self_attn): Qwen3Attention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=2048, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=2048, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Identity()\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "              (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "              (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
       "            )\n",
       "            (mlp): Qwen3MLP(\n",
       "              (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "              (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "            (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
       "        (rotary_emb): Qwen3RotaryEmbedding()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 用 PeftModel 把 adapter 权重叠加上去\n",
    "peft_model = PeftModel.from_pretrained(model, adapter_dir)\n",
    "# 将模型移动至设备\n",
    "peft_model = peft_model.to(device)\n",
    "peft_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1187/1187 [09:41<00:00,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.4516, Hits@3: 0.5350, Hits@10: 0.5948, MRR: 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hits1, hits3, hits10, mrr = evaluate_model(peft_model, tokenizer, valid_df, train_df, fewshot_k=3)\n",
    "print(f\"Hits@1: {hits1:.4f}, Hits@3: {hits3:.4f}, Hits@10: {hits10:.4f}, MRR: {mrr:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kgc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
