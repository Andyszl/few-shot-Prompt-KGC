{
  "best_global_step": 50,
  "best_metric": 1.1696335077285767,
  "best_model_checkpoint": "./outputs/checkpoint-50",
  "epoch": 12.639118457300276,
  "eval_steps": 50,
  "global_step": 3450,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03673094582185491,
      "grad_norm": 5.856680870056152,
      "learning_rate": 9.996691176470589e-05,
      "loss": 2.0659,
      "step": 10
    },
    {
      "epoch": 0.07346189164370982,
      "grad_norm": 4.713665962219238,
      "learning_rate": 9.993014705882353e-05,
      "loss": 1.39,
      "step": 20
    },
    {
      "epoch": 0.11019283746556474,
      "grad_norm": 3.4004430770874023,
      "learning_rate": 9.989338235294118e-05,
      "loss": 1.2932,
      "step": 30
    },
    {
      "epoch": 0.14692378328741965,
      "grad_norm": 2.785348415374756,
      "learning_rate": 9.985661764705882e-05,
      "loss": 1.1759,
      "step": 40
    },
    {
      "epoch": 0.18365472910927455,
      "grad_norm": 2.9693567752838135,
      "learning_rate": 9.981985294117647e-05,
      "loss": 1.1202,
      "step": 50
    },
    {
      "epoch": 0.18365472910927455,
      "eval_loss": 1.1696335077285767,
      "eval_runtime": 32.9276,
      "eval_samples_per_second": 36.049,
      "eval_steps_per_second": 4.525,
      "step": 50
    },
    {
      "epoch": 0.22038567493112948,
      "grad_norm": 2.321604013442993,
      "learning_rate": 9.978308823529412e-05,
      "loss": 1.0263,
      "step": 60
    },
    {
      "epoch": 0.2571166207529844,
      "grad_norm": 2.866220474243164,
      "learning_rate": 9.974632352941176e-05,
      "loss": 0.8806,
      "step": 70
    },
    {
      "epoch": 0.2938475665748393,
      "grad_norm": 3.948338031768799,
      "learning_rate": 9.970955882352942e-05,
      "loss": 1.2054,
      "step": 80
    },
    {
      "epoch": 0.3305785123966942,
      "grad_norm": 4.621361255645752,
      "learning_rate": 9.967279411764706e-05,
      "loss": 0.9097,
      "step": 90
    },
    {
      "epoch": 0.3673094582185491,
      "grad_norm": 3.415426254272461,
      "learning_rate": 9.963602941176471e-05,
      "loss": 0.9763,
      "step": 100
    },
    {
      "epoch": 0.3673094582185491,
      "eval_loss": 1.0975266695022583,
      "eval_runtime": 32.6319,
      "eval_samples_per_second": 36.375,
      "eval_steps_per_second": 4.566,
      "step": 100
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 2.7778472900390625,
      "learning_rate": 9.959926470588236e-05,
      "loss": 0.941,
      "step": 110
    },
    {
      "epoch": 0.44077134986225897,
      "grad_norm": 3.993023157119751,
      "learning_rate": 9.95625e-05,
      "loss": 0.9131,
      "step": 120
    },
    {
      "epoch": 0.47750229568411384,
      "grad_norm": 5.21882963180542,
      "learning_rate": 9.952573529411765e-05,
      "loss": 0.9182,
      "step": 130
    },
    {
      "epoch": 0.5142332415059688,
      "grad_norm": 4.30285120010376,
      "learning_rate": 9.948897058823529e-05,
      "loss": 0.8974,
      "step": 140
    },
    {
      "epoch": 0.5509641873278237,
      "grad_norm": 4.090346813201904,
      "learning_rate": 9.945220588235295e-05,
      "loss": 0.8775,
      "step": 150
    },
    {
      "epoch": 0.5509641873278237,
      "eval_loss": 1.0675424337387085,
      "eval_runtime": 32.6344,
      "eval_samples_per_second": 36.373,
      "eval_steps_per_second": 4.566,
      "step": 150
    },
    {
      "epoch": 0.5876951331496786,
      "grad_norm": 4.758708953857422,
      "learning_rate": 9.94154411764706e-05,
      "loss": 0.9512,
      "step": 160
    },
    {
      "epoch": 0.6244260789715336,
      "grad_norm": 4.474963665008545,
      "learning_rate": 9.937867647058824e-05,
      "loss": 0.9323,
      "step": 170
    },
    {
      "epoch": 0.6611570247933884,
      "grad_norm": 3.694777488708496,
      "learning_rate": 9.934191176470589e-05,
      "loss": 0.9225,
      "step": 180
    },
    {
      "epoch": 0.6978879706152433,
      "grad_norm": 4.464106559753418,
      "learning_rate": 9.930514705882353e-05,
      "loss": 0.7262,
      "step": 190
    },
    {
      "epoch": 0.7346189164370982,
      "grad_norm": 5.8573222160339355,
      "learning_rate": 9.926838235294118e-05,
      "loss": 0.9285,
      "step": 200
    },
    {
      "epoch": 0.7346189164370982,
      "eval_loss": 1.0247629880905151,
      "eval_runtime": 32.7288,
      "eval_samples_per_second": 36.268,
      "eval_steps_per_second": 4.553,
      "step": 200
    },
    {
      "epoch": 0.7713498622589532,
      "grad_norm": 4.695018768310547,
      "learning_rate": 9.923161764705882e-05,
      "loss": 0.76,
      "step": 210
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 3.985699415206909,
      "learning_rate": 9.919485294117647e-05,
      "loss": 0.9194,
      "step": 220
    },
    {
      "epoch": 0.8448117539026629,
      "grad_norm": 3.10659122467041,
      "learning_rate": 9.915808823529413e-05,
      "loss": 0.6865,
      "step": 230
    },
    {
      "epoch": 0.8815426997245179,
      "grad_norm": 4.030872344970703,
      "learning_rate": 9.912132352941177e-05,
      "loss": 0.8414,
      "step": 240
    },
    {
      "epoch": 0.9182736455463728,
      "grad_norm": 4.732781410217285,
      "learning_rate": 9.908455882352942e-05,
      "loss": 0.8474,
      "step": 250
    },
    {
      "epoch": 0.9182736455463728,
      "eval_loss": 1.012956976890564,
      "eval_runtime": 32.7094,
      "eval_samples_per_second": 36.289,
      "eval_steps_per_second": 4.555,
      "step": 250
    },
    {
      "epoch": 0.9550045913682277,
      "grad_norm": 4.650861740112305,
      "learning_rate": 9.904779411764706e-05,
      "loss": 0.7535,
      "step": 260
    },
    {
      "epoch": 0.9917355371900827,
      "grad_norm": 5.37391471862793,
      "learning_rate": 9.901102941176471e-05,
      "loss": 0.7799,
      "step": 270
    },
    {
      "epoch": 1.0257116620752984,
      "grad_norm": 6.000741481781006,
      "learning_rate": 9.897426470588235e-05,
      "loss": 0.8661,
      "step": 280
    },
    {
      "epoch": 1.0624426078971534,
      "grad_norm": 6.103728294372559,
      "learning_rate": 9.89375e-05,
      "loss": 0.6262,
      "step": 290
    },
    {
      "epoch": 1.0991735537190084,
      "grad_norm": 4.584035396575928,
      "learning_rate": 9.890073529411766e-05,
      "loss": 0.6141,
      "step": 300
    },
    {
      "epoch": 1.0991735537190084,
      "eval_loss": 1.0076593160629272,
      "eval_runtime": 32.9904,
      "eval_samples_per_second": 35.98,
      "eval_steps_per_second": 4.516,
      "step": 300
    },
    {
      "epoch": 1.1359044995408631,
      "grad_norm": 4.814003944396973,
      "learning_rate": 9.88639705882353e-05,
      "loss": 0.6245,
      "step": 310
    },
    {
      "epoch": 1.1726354453627181,
      "grad_norm": 6.480805397033691,
      "learning_rate": 9.882720588235295e-05,
      "loss": 0.6516,
      "step": 320
    },
    {
      "epoch": 1.209366391184573,
      "grad_norm": 5.493929386138916,
      "learning_rate": 9.87904411764706e-05,
      "loss": 0.5383,
      "step": 330
    },
    {
      "epoch": 1.2460973370064279,
      "grad_norm": 5.356457233428955,
      "learning_rate": 9.875367647058824e-05,
      "loss": 0.6389,
      "step": 340
    },
    {
      "epoch": 1.2828282828282829,
      "grad_norm": 5.315889835357666,
      "learning_rate": 9.871691176470589e-05,
      "loss": 0.5472,
      "step": 350
    },
    {
      "epoch": 1.2828282828282829,
      "eval_loss": 0.9878066182136536,
      "eval_runtime": 33.5087,
      "eval_samples_per_second": 35.424,
      "eval_steps_per_second": 4.447,
      "step": 350
    },
    {
      "epoch": 1.3195592286501379,
      "grad_norm": 6.136620044708252,
      "learning_rate": 9.868014705882353e-05,
      "loss": 0.5805,
      "step": 360
    },
    {
      "epoch": 1.3562901744719926,
      "grad_norm": 6.254191875457764,
      "learning_rate": 9.864338235294119e-05,
      "loss": 0.6716,
      "step": 370
    },
    {
      "epoch": 1.3930211202938476,
      "grad_norm": 5.67423677444458,
      "learning_rate": 9.860661764705883e-05,
      "loss": 0.6927,
      "step": 380
    },
    {
      "epoch": 1.4297520661157024,
      "grad_norm": 7.969796657562256,
      "learning_rate": 9.856985294117648e-05,
      "loss": 0.6958,
      "step": 390
    },
    {
      "epoch": 1.4664830119375574,
      "grad_norm": 4.875154972076416,
      "learning_rate": 9.853308823529413e-05,
      "loss": 0.5529,
      "step": 400
    },
    {
      "epoch": 1.4664830119375574,
      "eval_loss": 0.9725937247276306,
      "eval_runtime": 33.5946,
      "eval_samples_per_second": 35.333,
      "eval_steps_per_second": 4.435,
      "step": 400
    },
    {
      "epoch": 1.5032139577594124,
      "grad_norm": 6.128445625305176,
      "learning_rate": 9.849632352941177e-05,
      "loss": 0.6509,
      "step": 410
    },
    {
      "epoch": 1.5399449035812673,
      "grad_norm": 5.59340763092041,
      "learning_rate": 9.845955882352942e-05,
      "loss": 0.5237,
      "step": 420
    },
    {
      "epoch": 1.576675849403122,
      "grad_norm": 5.9676384925842285,
      "learning_rate": 9.842279411764706e-05,
      "loss": 0.5318,
      "step": 430
    },
    {
      "epoch": 1.613406795224977,
      "grad_norm": 6.364933967590332,
      "learning_rate": 9.838602941176471e-05,
      "loss": 0.5284,
      "step": 440
    },
    {
      "epoch": 1.6501377410468319,
      "grad_norm": 7.17756462097168,
      "learning_rate": 9.834926470588237e-05,
      "loss": 0.5278,
      "step": 450
    },
    {
      "epoch": 1.6501377410468319,
      "eval_loss": 0.9803275465965271,
      "eval_runtime": 33.5557,
      "eval_samples_per_second": 35.374,
      "eval_steps_per_second": 4.44,
      "step": 450
    },
    {
      "epoch": 1.6868686868686869,
      "grad_norm": 6.332273006439209,
      "learning_rate": 9.831250000000001e-05,
      "loss": 0.6718,
      "step": 460
    },
    {
      "epoch": 1.7235996326905418,
      "grad_norm": 4.4793620109558105,
      "learning_rate": 9.827573529411766e-05,
      "loss": 0.5457,
      "step": 470
    },
    {
      "epoch": 1.7603305785123968,
      "grad_norm": 8.063905715942383,
      "learning_rate": 9.82389705882353e-05,
      "loss": 0.6306,
      "step": 480
    },
    {
      "epoch": 1.7970615243342516,
      "grad_norm": 6.158483505249023,
      "learning_rate": 9.820220588235295e-05,
      "loss": 0.5203,
      "step": 490
    },
    {
      "epoch": 1.8337924701561064,
      "grad_norm": 5.586578369140625,
      "learning_rate": 9.816544117647059e-05,
      "loss": 0.6069,
      "step": 500
    },
    {
      "epoch": 1.8337924701561064,
      "eval_loss": 0.964713454246521,
      "eval_runtime": 33.5669,
      "eval_samples_per_second": 35.362,
      "eval_steps_per_second": 4.439,
      "step": 500
    },
    {
      "epoch": 1.8705234159779613,
      "grad_norm": 4.427137851715088,
      "learning_rate": 9.812867647058824e-05,
      "loss": 0.5377,
      "step": 510
    },
    {
      "epoch": 1.9072543617998163,
      "grad_norm": 6.860030651092529,
      "learning_rate": 9.80919117647059e-05,
      "loss": 0.5152,
      "step": 520
    },
    {
      "epoch": 1.9439853076216713,
      "grad_norm": 4.274284362792969,
      "learning_rate": 9.805514705882354e-05,
      "loss": 0.5522,
      "step": 530
    },
    {
      "epoch": 1.9807162534435263,
      "grad_norm": 6.672605514526367,
      "learning_rate": 9.801838235294119e-05,
      "loss": 0.548,
      "step": 540
    },
    {
      "epoch": 2.014692378328742,
      "grad_norm": 6.8912882804870605,
      "learning_rate": 9.798161764705883e-05,
      "loss": 0.5192,
      "step": 550
    },
    {
      "epoch": 2.014692378328742,
      "eval_loss": 0.9330836534500122,
      "eval_runtime": 32.6633,
      "eval_samples_per_second": 36.341,
      "eval_steps_per_second": 4.562,
      "step": 550
    },
    {
      "epoch": 2.051423324150597,
      "grad_norm": 4.262485504150391,
      "learning_rate": 9.794485294117648e-05,
      "loss": 0.531,
      "step": 560
    },
    {
      "epoch": 2.088154269972452,
      "grad_norm": 8.48047924041748,
      "learning_rate": 9.790808823529412e-05,
      "loss": 0.4879,
      "step": 570
    },
    {
      "epoch": 2.124885215794307,
      "grad_norm": 7.551414966583252,
      "learning_rate": 9.787132352941177e-05,
      "loss": 0.5007,
      "step": 580
    },
    {
      "epoch": 2.1616161616161618,
      "grad_norm": 3.3016884326934814,
      "learning_rate": 9.783455882352941e-05,
      "loss": 0.4697,
      "step": 590
    },
    {
      "epoch": 2.1983471074380168,
      "grad_norm": 6.5082268714904785,
      "learning_rate": 9.779779411764707e-05,
      "loss": 0.4114,
      "step": 600
    },
    {
      "epoch": 2.1983471074380168,
      "eval_loss": 0.9844725131988525,
      "eval_runtime": 32.6425,
      "eval_samples_per_second": 36.364,
      "eval_steps_per_second": 4.565,
      "step": 600
    },
    {
      "epoch": 2.2350780532598713,
      "grad_norm": 3.6612884998321533,
      "learning_rate": 9.776102941176472e-05,
      "loss": 0.431,
      "step": 610
    },
    {
      "epoch": 2.2718089990817263,
      "grad_norm": 4.71645975112915,
      "learning_rate": 9.772426470588236e-05,
      "loss": 0.3909,
      "step": 620
    },
    {
      "epoch": 2.3085399449035813,
      "grad_norm": 6.423635482788086,
      "learning_rate": 9.768750000000001e-05,
      "loss": 0.5101,
      "step": 630
    },
    {
      "epoch": 2.3452708907254363,
      "grad_norm": 6.335910320281982,
      "learning_rate": 9.765073529411765e-05,
      "loss": 0.4477,
      "step": 640
    },
    {
      "epoch": 2.3820018365472913,
      "grad_norm": 7.641993045806885,
      "learning_rate": 9.76139705882353e-05,
      "loss": 0.4742,
      "step": 650
    },
    {
      "epoch": 2.3820018365472913,
      "eval_loss": 0.9265380501747131,
      "eval_runtime": 32.6358,
      "eval_samples_per_second": 36.371,
      "eval_steps_per_second": 4.566,
      "step": 650
    },
    {
      "epoch": 2.418732782369146,
      "grad_norm": 4.5506415367126465,
      "learning_rate": 9.757720588235295e-05,
      "loss": 0.3837,
      "step": 660
    },
    {
      "epoch": 2.455463728191001,
      "grad_norm": 4.430692672729492,
      "learning_rate": 9.75404411764706e-05,
      "loss": 0.4738,
      "step": 670
    },
    {
      "epoch": 2.4921946740128558,
      "grad_norm": 4.979239463806152,
      "learning_rate": 9.750367647058825e-05,
      "loss": 0.4023,
      "step": 680
    },
    {
      "epoch": 2.5289256198347108,
      "grad_norm": 5.758579730987549,
      "learning_rate": 9.746691176470588e-05,
      "loss": 0.4664,
      "step": 690
    },
    {
      "epoch": 2.5656565656565657,
      "grad_norm": 5.472966194152832,
      "learning_rate": 9.743014705882353e-05,
      "loss": 0.377,
      "step": 700
    },
    {
      "epoch": 2.5656565656565657,
      "eval_loss": 0.9598812460899353,
      "eval_runtime": 32.6534,
      "eval_samples_per_second": 36.352,
      "eval_steps_per_second": 4.563,
      "step": 700
    },
    {
      "epoch": 2.6023875114784207,
      "grad_norm": 6.778362274169922,
      "learning_rate": 9.739338235294117e-05,
      "loss": 0.4052,
      "step": 710
    },
    {
      "epoch": 2.6391184573002757,
      "grad_norm": 4.993110656738281,
      "learning_rate": 9.735661764705882e-05,
      "loss": 0.4264,
      "step": 720
    },
    {
      "epoch": 2.6758494031221303,
      "grad_norm": 4.721892356872559,
      "learning_rate": 9.731985294117648e-05,
      "loss": 0.4205,
      "step": 730
    },
    {
      "epoch": 2.7125803489439853,
      "grad_norm": 6.717843055725098,
      "learning_rate": 9.728308823529412e-05,
      "loss": 0.3549,
      "step": 740
    },
    {
      "epoch": 2.7493112947658402,
      "grad_norm": 3.788750648498535,
      "learning_rate": 9.724632352941177e-05,
      "loss": 0.497,
      "step": 750
    },
    {
      "epoch": 2.7493112947658402,
      "eval_loss": 0.9134942889213562,
      "eval_runtime": 33.6327,
      "eval_samples_per_second": 35.293,
      "eval_steps_per_second": 4.43,
      "step": 750
    },
    {
      "epoch": 2.7860422405876952,
      "grad_norm": 4.995515823364258,
      "learning_rate": 9.720955882352941e-05,
      "loss": 0.3387,
      "step": 760
    },
    {
      "epoch": 2.8227731864095498,
      "grad_norm": 5.755503177642822,
      "learning_rate": 9.717279411764706e-05,
      "loss": 0.4494,
      "step": 770
    },
    {
      "epoch": 2.8595041322314048,
      "grad_norm": 5.3560638427734375,
      "learning_rate": 9.71360294117647e-05,
      "loss": 0.3769,
      "step": 780
    },
    {
      "epoch": 2.8962350780532597,
      "grad_norm": 3.98350191116333,
      "learning_rate": 9.709926470588235e-05,
      "loss": 0.4403,
      "step": 790
    },
    {
      "epoch": 2.9329660238751147,
      "grad_norm": 5.5578932762146,
      "learning_rate": 9.70625e-05,
      "loss": 0.433,
      "step": 800
    },
    {
      "epoch": 2.9329660238751147,
      "eval_loss": 0.9784461259841919,
      "eval_runtime": 33.6151,
      "eval_samples_per_second": 35.312,
      "eval_steps_per_second": 4.433,
      "step": 800
    },
    {
      "epoch": 2.9696969696969697,
      "grad_norm": 5.347299575805664,
      "learning_rate": 9.702573529411765e-05,
      "loss": 0.3752,
      "step": 810
    },
    {
      "epoch": 3.0036730945821857,
      "grad_norm": 6.471491813659668,
      "learning_rate": 9.69889705882353e-05,
      "loss": 0.4496,
      "step": 820
    },
    {
      "epoch": 3.04040404040404,
      "grad_norm": 7.086663246154785,
      "learning_rate": 9.695220588235294e-05,
      "loss": 0.4074,
      "step": 830
    },
    {
      "epoch": 3.077134986225895,
      "grad_norm": 5.8225507736206055,
      "learning_rate": 9.691544117647059e-05,
      "loss": 0.2848,
      "step": 840
    },
    {
      "epoch": 3.11386593204775,
      "grad_norm": 5.051563739776611,
      "learning_rate": 9.687867647058823e-05,
      "loss": 0.3271,
      "step": 850
    },
    {
      "epoch": 3.11386593204775,
      "eval_loss": 0.9773937463760376,
      "eval_runtime": 33.6502,
      "eval_samples_per_second": 35.275,
      "eval_steps_per_second": 4.428,
      "step": 850
    },
    {
      "epoch": 3.150596877869605,
      "grad_norm": 6.353227138519287,
      "learning_rate": 9.684191176470588e-05,
      "loss": 0.3655,
      "step": 860
    },
    {
      "epoch": 3.18732782369146,
      "grad_norm": 6.539187431335449,
      "learning_rate": 9.680514705882353e-05,
      "loss": 0.3908,
      "step": 870
    },
    {
      "epoch": 3.224058769513315,
      "grad_norm": 4.9646992683410645,
      "learning_rate": 9.676838235294118e-05,
      "loss": 0.3146,
      "step": 880
    },
    {
      "epoch": 3.2607897153351697,
      "grad_norm": 6.411111354827881,
      "learning_rate": 9.673161764705883e-05,
      "loss": 0.3847,
      "step": 890
    },
    {
      "epoch": 3.2975206611570247,
      "grad_norm": 5.653909683227539,
      "learning_rate": 9.669485294117648e-05,
      "loss": 0.3692,
      "step": 900
    },
    {
      "epoch": 3.2975206611570247,
      "eval_loss": 0.9688672423362732,
      "eval_runtime": 33.6186,
      "eval_samples_per_second": 35.308,
      "eval_steps_per_second": 4.432,
      "step": 900
    },
    {
      "epoch": 3.3342516069788797,
      "grad_norm": 5.899026870727539,
      "learning_rate": 9.665808823529412e-05,
      "loss": 0.3553,
      "step": 910
    },
    {
      "epoch": 3.3709825528007347,
      "grad_norm": 5.590170860290527,
      "learning_rate": 9.662132352941177e-05,
      "loss": 0.3252,
      "step": 920
    },
    {
      "epoch": 3.4077134986225897,
      "grad_norm": 4.785136699676514,
      "learning_rate": 9.658455882352941e-05,
      "loss": 0.3382,
      "step": 930
    },
    {
      "epoch": 3.4444444444444446,
      "grad_norm": 5.709113597869873,
      "learning_rate": 9.654779411764706e-05,
      "loss": 0.3736,
      "step": 940
    },
    {
      "epoch": 3.481175390266299,
      "grad_norm": 10.176945686340332,
      "learning_rate": 9.65110294117647e-05,
      "loss": 0.3348,
      "step": 950
    },
    {
      "epoch": 3.481175390266299,
      "eval_loss": 0.9360337257385254,
      "eval_runtime": 33.5558,
      "eval_samples_per_second": 35.374,
      "eval_steps_per_second": 4.44,
      "step": 950
    },
    {
      "epoch": 3.517906336088154,
      "grad_norm": 5.645407199859619,
      "learning_rate": 9.647426470588236e-05,
      "loss": 0.2776,
      "step": 960
    },
    {
      "epoch": 3.554637281910009,
      "grad_norm": 7.844645023345947,
      "learning_rate": 9.64375e-05,
      "loss": 0.4094,
      "step": 970
    },
    {
      "epoch": 3.591368227731864,
      "grad_norm": 4.864295959472656,
      "learning_rate": 9.640073529411765e-05,
      "loss": 0.3463,
      "step": 980
    },
    {
      "epoch": 3.628099173553719,
      "grad_norm": 5.629849910736084,
      "learning_rate": 9.63639705882353e-05,
      "loss": 0.2741,
      "step": 990
    },
    {
      "epoch": 3.6648301193755737,
      "grad_norm": 8.303524017333984,
      "learning_rate": 9.632720588235294e-05,
      "loss": 0.415,
      "step": 1000
    },
    {
      "epoch": 3.6648301193755737,
      "eval_loss": 0.9551587700843811,
      "eval_runtime": 32.8311,
      "eval_samples_per_second": 36.155,
      "eval_steps_per_second": 4.538,
      "step": 1000
    },
    {
      "epoch": 3.7015610651974287,
      "grad_norm": 3.568678379058838,
      "learning_rate": 9.629044117647059e-05,
      "loss": 0.2918,
      "step": 1010
    },
    {
      "epoch": 3.7382920110192837,
      "grad_norm": 5.825601100921631,
      "learning_rate": 9.625367647058823e-05,
      "loss": 0.3453,
      "step": 1020
    },
    {
      "epoch": 3.7750229568411386,
      "grad_norm": 5.077935218811035,
      "learning_rate": 9.621691176470589e-05,
      "loss": 0.369,
      "step": 1030
    },
    {
      "epoch": 3.8117539026629936,
      "grad_norm": 6.545365810394287,
      "learning_rate": 9.618014705882354e-05,
      "loss": 0.3563,
      "step": 1040
    },
    {
      "epoch": 3.8484848484848486,
      "grad_norm": 3.3918659687042236,
      "learning_rate": 9.614338235294118e-05,
      "loss": 0.3025,
      "step": 1050
    },
    {
      "epoch": 3.8484848484848486,
      "eval_loss": 0.9302847981452942,
      "eval_runtime": 33.693,
      "eval_samples_per_second": 35.23,
      "eval_steps_per_second": 4.422,
      "step": 1050
    },
    {
      "epoch": 3.8852157943067036,
      "grad_norm": 6.464101791381836,
      "learning_rate": 9.610661764705883e-05,
      "loss": 0.4287,
      "step": 1060
    },
    {
      "epoch": 3.921946740128558,
      "grad_norm": 4.863832950592041,
      "learning_rate": 9.606985294117647e-05,
      "loss": 0.4054,
      "step": 1070
    },
    {
      "epoch": 3.958677685950413,
      "grad_norm": 3.51867413520813,
      "learning_rate": 9.603308823529412e-05,
      "loss": 0.2605,
      "step": 1080
    },
    {
      "epoch": 3.995408631772268,
      "grad_norm": 8.664925575256348,
      "learning_rate": 9.599632352941176e-05,
      "loss": 0.4238,
      "step": 1090
    },
    {
      "epoch": 4.029384756657484,
      "grad_norm": 5.532196044921875,
      "learning_rate": 9.595955882352941e-05,
      "loss": 0.2495,
      "step": 1100
    },
    {
      "epoch": 4.029384756657484,
      "eval_loss": 0.9439250826835632,
      "eval_runtime": 33.6233,
      "eval_samples_per_second": 35.303,
      "eval_steps_per_second": 4.431,
      "step": 1100
    },
    {
      "epoch": 4.066115702479339,
      "grad_norm": 6.343580722808838,
      "learning_rate": 9.592279411764707e-05,
      "loss": 0.2891,
      "step": 1110
    },
    {
      "epoch": 4.102846648301194,
      "grad_norm": 5.1544413566589355,
      "learning_rate": 9.588602941176471e-05,
      "loss": 0.3305,
      "step": 1120
    },
    {
      "epoch": 4.139577594123049,
      "grad_norm": 6.015890121459961,
      "learning_rate": 9.584926470588236e-05,
      "loss": 0.29,
      "step": 1130
    },
    {
      "epoch": 4.176308539944904,
      "grad_norm": 6.531774997711182,
      "learning_rate": 9.58125e-05,
      "loss": 0.2814,
      "step": 1140
    },
    {
      "epoch": 4.213039485766759,
      "grad_norm": 6.662056922912598,
      "learning_rate": 9.577573529411765e-05,
      "loss": 0.3056,
      "step": 1150
    },
    {
      "epoch": 4.213039485766759,
      "eval_loss": 0.9567776322364807,
      "eval_runtime": 33.6036,
      "eval_samples_per_second": 35.324,
      "eval_steps_per_second": 4.434,
      "step": 1150
    },
    {
      "epoch": 4.249770431588614,
      "grad_norm": 4.999387264251709,
      "learning_rate": 9.57389705882353e-05,
      "loss": 0.2608,
      "step": 1160
    },
    {
      "epoch": 4.2865013774104685,
      "grad_norm": 8.006993293762207,
      "learning_rate": 9.570220588235294e-05,
      "loss": 0.3072,
      "step": 1170
    },
    {
      "epoch": 4.3232323232323235,
      "grad_norm": 4.515589714050293,
      "learning_rate": 9.56654411764706e-05,
      "loss": 0.2897,
      "step": 1180
    },
    {
      "epoch": 4.3599632690541785,
      "grad_norm": 5.294859409332275,
      "learning_rate": 9.562867647058825e-05,
      "loss": 0.3098,
      "step": 1190
    },
    {
      "epoch": 4.3966942148760335,
      "grad_norm": 8.872821807861328,
      "learning_rate": 9.559191176470589e-05,
      "loss": 0.2641,
      "step": 1200
    },
    {
      "epoch": 4.3966942148760335,
      "eval_loss": 0.9583247900009155,
      "eval_runtime": 33.6078,
      "eval_samples_per_second": 35.319,
      "eval_steps_per_second": 4.433,
      "step": 1200
    },
    {
      "epoch": 4.433425160697888,
      "grad_norm": 4.97227668762207,
      "learning_rate": 9.555514705882354e-05,
      "loss": 0.2647,
      "step": 1210
    },
    {
      "epoch": 4.470156106519743,
      "grad_norm": 3.3430559635162354,
      "learning_rate": 9.551838235294118e-05,
      "loss": 0.3511,
      "step": 1220
    },
    {
      "epoch": 4.506887052341598,
      "grad_norm": 6.492629528045654,
      "learning_rate": 9.548161764705883e-05,
      "loss": 0.2881,
      "step": 1230
    },
    {
      "epoch": 4.543617998163453,
      "grad_norm": 5.802737236022949,
      "learning_rate": 9.544485294117647e-05,
      "loss": 0.3505,
      "step": 1240
    },
    {
      "epoch": 4.580348943985308,
      "grad_norm": 4.613150119781494,
      "learning_rate": 9.540808823529413e-05,
      "loss": 0.2899,
      "step": 1250
    },
    {
      "epoch": 4.580348943985308,
      "eval_loss": 0.9259881377220154,
      "eval_runtime": 33.5823,
      "eval_samples_per_second": 35.346,
      "eval_steps_per_second": 4.437,
      "step": 1250
    },
    {
      "epoch": 4.6170798898071626,
      "grad_norm": 4.365199565887451,
      "learning_rate": 9.537132352941178e-05,
      "loss": 0.3293,
      "step": 1260
    },
    {
      "epoch": 4.6538108356290175,
      "grad_norm": 5.711389064788818,
      "learning_rate": 9.533455882352942e-05,
      "loss": 0.3093,
      "step": 1270
    },
    {
      "epoch": 4.6905417814508725,
      "grad_norm": 5.257623195648193,
      "learning_rate": 9.529779411764707e-05,
      "loss": 0.2819,
      "step": 1280
    },
    {
      "epoch": 4.7272727272727275,
      "grad_norm": 3.8239684104919434,
      "learning_rate": 9.526102941176471e-05,
      "loss": 0.333,
      "step": 1290
    },
    {
      "epoch": 4.7640036730945825,
      "grad_norm": 5.387397289276123,
      "learning_rate": 9.522426470588236e-05,
      "loss": 0.3087,
      "step": 1300
    },
    {
      "epoch": 4.7640036730945825,
      "eval_loss": 0.9623046517372131,
      "eval_runtime": 33.5748,
      "eval_samples_per_second": 35.354,
      "eval_steps_per_second": 4.438,
      "step": 1300
    },
    {
      "epoch": 4.800734618916437,
      "grad_norm": 7.049424171447754,
      "learning_rate": 9.51875e-05,
      "loss": 0.2717,
      "step": 1310
    },
    {
      "epoch": 4.837465564738292,
      "grad_norm": 8.132328987121582,
      "learning_rate": 9.515073529411765e-05,
      "loss": 0.297,
      "step": 1320
    },
    {
      "epoch": 4.874196510560147,
      "grad_norm": 4.0385823249816895,
      "learning_rate": 9.511397058823531e-05,
      "loss": 0.229,
      "step": 1330
    },
    {
      "epoch": 4.910927456382002,
      "grad_norm": 4.306978225708008,
      "learning_rate": 9.507720588235295e-05,
      "loss": 0.2785,
      "step": 1340
    },
    {
      "epoch": 4.9476584022038566,
      "grad_norm": 4.641031265258789,
      "learning_rate": 9.50404411764706e-05,
      "loss": 0.2645,
      "step": 1350
    },
    {
      "epoch": 4.9476584022038566,
      "eval_loss": 0.9303709864616394,
      "eval_runtime": 33.64,
      "eval_samples_per_second": 35.285,
      "eval_steps_per_second": 4.429,
      "step": 1350
    },
    {
      "epoch": 4.9843893480257115,
      "grad_norm": 5.650813102722168,
      "learning_rate": 9.500367647058824e-05,
      "loss": 0.2659,
      "step": 1360
    },
    {
      "epoch": 5.0183654729109275,
      "grad_norm": 4.726614952087402,
      "learning_rate": 9.496691176470589e-05,
      "loss": 0.2879,
      "step": 1370
    },
    {
      "epoch": 5.0550964187327825,
      "grad_norm": 4.316624641418457,
      "learning_rate": 9.493014705882353e-05,
      "loss": 0.2075,
      "step": 1380
    },
    {
      "epoch": 5.0918273645546375,
      "grad_norm": 5.972236156463623,
      "learning_rate": 9.489338235294118e-05,
      "loss": 0.3114,
      "step": 1390
    },
    {
      "epoch": 5.1285583103764925,
      "grad_norm": 7.102478504180908,
      "learning_rate": 9.485661764705884e-05,
      "loss": 0.2259,
      "step": 1400
    },
    {
      "epoch": 5.1285583103764925,
      "eval_loss": 1.02351975440979,
      "eval_runtime": 33.5803,
      "eval_samples_per_second": 35.348,
      "eval_steps_per_second": 4.437,
      "step": 1400
    },
    {
      "epoch": 5.1652892561983474,
      "grad_norm": 6.032559871673584,
      "learning_rate": 9.481985294117648e-05,
      "loss": 0.2534,
      "step": 1410
    },
    {
      "epoch": 5.202020202020202,
      "grad_norm": 5.64008092880249,
      "learning_rate": 9.478308823529413e-05,
      "loss": 0.2683,
      "step": 1420
    },
    {
      "epoch": 5.2387511478420565,
      "grad_norm": 8.931668281555176,
      "learning_rate": 9.474632352941177e-05,
      "loss": 0.2168,
      "step": 1430
    },
    {
      "epoch": 5.2754820936639115,
      "grad_norm": 3.4781360626220703,
      "learning_rate": 9.470955882352942e-05,
      "loss": 0.2181,
      "step": 1440
    },
    {
      "epoch": 5.3122130394857665,
      "grad_norm": 6.91257905960083,
      "learning_rate": 9.467279411764707e-05,
      "loss": 0.2762,
      "step": 1450
    },
    {
      "epoch": 5.3122130394857665,
      "eval_loss": 0.9529551863670349,
      "eval_runtime": 33.61,
      "eval_samples_per_second": 35.317,
      "eval_steps_per_second": 4.433,
      "step": 1450
    },
    {
      "epoch": 5.3489439853076215,
      "grad_norm": 4.848637580871582,
      "learning_rate": 9.463602941176471e-05,
      "loss": 0.2331,
      "step": 1460
    },
    {
      "epoch": 5.3856749311294765,
      "grad_norm": 6.228209495544434,
      "learning_rate": 9.459926470588236e-05,
      "loss": 0.2163,
      "step": 1470
    },
    {
      "epoch": 5.4224058769513315,
      "grad_norm": 4.137213230133057,
      "learning_rate": 9.456250000000001e-05,
      "loss": 0.1979,
      "step": 1480
    },
    {
      "epoch": 5.4591368227731865,
      "grad_norm": 6.017092704772949,
      "learning_rate": 9.452573529411766e-05,
      "loss": 0.2611,
      "step": 1490
    },
    {
      "epoch": 5.4958677685950414,
      "grad_norm": 5.90925931930542,
      "learning_rate": 9.44889705882353e-05,
      "loss": 0.2795,
      "step": 1500
    },
    {
      "epoch": 5.4958677685950414,
      "eval_loss": 0.9710015654563904,
      "eval_runtime": 33.6101,
      "eval_samples_per_second": 35.317,
      "eval_steps_per_second": 4.433,
      "step": 1500
    },
    {
      "epoch": 5.532598714416896,
      "grad_norm": 3.8902275562286377,
      "learning_rate": 9.445220588235295e-05,
      "loss": 0.2264,
      "step": 1510
    },
    {
      "epoch": 5.569329660238751,
      "grad_norm": 5.503519058227539,
      "learning_rate": 9.44154411764706e-05,
      "loss": 0.2406,
      "step": 1520
    },
    {
      "epoch": 5.606060606060606,
      "grad_norm": 3.9557738304138184,
      "learning_rate": 9.437867647058824e-05,
      "loss": 0.2407,
      "step": 1530
    },
    {
      "epoch": 5.6427915518824605,
      "grad_norm": 5.287912368774414,
      "learning_rate": 9.434191176470589e-05,
      "loss": 0.2746,
      "step": 1540
    },
    {
      "epoch": 5.6795224977043155,
      "grad_norm": 5.817972660064697,
      "learning_rate": 9.430514705882353e-05,
      "loss": 0.3193,
      "step": 1550
    },
    {
      "epoch": 5.6795224977043155,
      "eval_loss": 0.9627760648727417,
      "eval_runtime": 33.505,
      "eval_samples_per_second": 35.428,
      "eval_steps_per_second": 4.447,
      "step": 1550
    },
    {
      "epoch": 5.7162534435261705,
      "grad_norm": 5.168889999389648,
      "learning_rate": 9.426838235294118e-05,
      "loss": 0.2559,
      "step": 1560
    },
    {
      "epoch": 5.7529843893480255,
      "grad_norm": 6.099484443664551,
      "learning_rate": 9.423161764705882e-05,
      "loss": 0.2247,
      "step": 1570
    },
    {
      "epoch": 5.7897153351698805,
      "grad_norm": 5.730974197387695,
      "learning_rate": 9.419485294117647e-05,
      "loss": 0.2384,
      "step": 1580
    },
    {
      "epoch": 5.8264462809917354,
      "grad_norm": 6.563372611999512,
      "learning_rate": 9.415808823529411e-05,
      "loss": 0.226,
      "step": 1590
    },
    {
      "epoch": 5.86317722681359,
      "grad_norm": 8.486145973205566,
      "learning_rate": 9.412132352941176e-05,
      "loss": 0.2154,
      "step": 1600
    },
    {
      "epoch": 5.86317722681359,
      "eval_loss": 0.9756217002868652,
      "eval_runtime": 33.5787,
      "eval_samples_per_second": 35.35,
      "eval_steps_per_second": 4.437,
      "step": 1600
    },
    {
      "epoch": 5.899908172635445,
      "grad_norm": 4.316154479980469,
      "learning_rate": 9.408455882352942e-05,
      "loss": 0.245,
      "step": 1610
    },
    {
      "epoch": 5.9366391184573,
      "grad_norm": 6.1025471687316895,
      "learning_rate": 9.404779411764706e-05,
      "loss": 0.2479,
      "step": 1620
    },
    {
      "epoch": 5.973370064279155,
      "grad_norm": 5.395945072174072,
      "learning_rate": 9.401102941176471e-05,
      "loss": 0.2645,
      "step": 1630
    },
    {
      "epoch": 6.007346189164371,
      "grad_norm": 4.169856548309326,
      "learning_rate": 9.397426470588235e-05,
      "loss": 0.3965,
      "step": 1640
    },
    {
      "epoch": 6.044077134986226,
      "grad_norm": 4.011684417724609,
      "learning_rate": 9.39375e-05,
      "loss": 0.1964,
      "step": 1650
    },
    {
      "epoch": 6.044077134986226,
      "eval_loss": 1.0187989473342896,
      "eval_runtime": 33.6771,
      "eval_samples_per_second": 35.246,
      "eval_steps_per_second": 4.424,
      "step": 1650
    },
    {
      "epoch": 6.08080808080808,
      "grad_norm": 4.958868980407715,
      "learning_rate": 9.390073529411765e-05,
      "loss": 0.2182,
      "step": 1660
    },
    {
      "epoch": 6.117539026629935,
      "grad_norm": 4.1061177253723145,
      "learning_rate": 9.386397058823529e-05,
      "loss": 0.2038,
      "step": 1670
    },
    {
      "epoch": 6.15426997245179,
      "grad_norm": 4.4896769523620605,
      "learning_rate": 9.382720588235294e-05,
      "loss": 0.1701,
      "step": 1680
    },
    {
      "epoch": 6.191000918273645,
      "grad_norm": 3.2411296367645264,
      "learning_rate": 9.37904411764706e-05,
      "loss": 0.1972,
      "step": 1690
    },
    {
      "epoch": 6.2277318640955,
      "grad_norm": 6.334043979644775,
      "learning_rate": 9.375367647058824e-05,
      "loss": 0.2229,
      "step": 1700
    },
    {
      "epoch": 6.2277318640955,
      "eval_loss": 1.047049641609192,
      "eval_runtime": 33.5931,
      "eval_samples_per_second": 35.335,
      "eval_steps_per_second": 4.435,
      "step": 1700
    },
    {
      "epoch": 6.264462809917355,
      "grad_norm": 2.8677985668182373,
      "learning_rate": 9.371691176470589e-05,
      "loss": 0.1682,
      "step": 1710
    },
    {
      "epoch": 6.30119375573921,
      "grad_norm": 4.09780740737915,
      "learning_rate": 9.368014705882353e-05,
      "loss": 0.2065,
      "step": 1720
    },
    {
      "epoch": 6.337924701561065,
      "grad_norm": 4.367406368255615,
      "learning_rate": 9.364338235294118e-05,
      "loss": 0.2128,
      "step": 1730
    },
    {
      "epoch": 6.37465564738292,
      "grad_norm": 9.430908203125,
      "learning_rate": 9.360661764705882e-05,
      "loss": 0.242,
      "step": 1740
    },
    {
      "epoch": 6.411386593204775,
      "grad_norm": 4.5964179039001465,
      "learning_rate": 9.356985294117647e-05,
      "loss": 0.2064,
      "step": 1750
    },
    {
      "epoch": 6.411386593204775,
      "eval_loss": 0.9938313961029053,
      "eval_runtime": 33.6196,
      "eval_samples_per_second": 35.307,
      "eval_steps_per_second": 4.432,
      "step": 1750
    },
    {
      "epoch": 6.44811753902663,
      "grad_norm": 8.229228973388672,
      "learning_rate": 9.353308823529413e-05,
      "loss": 0.2708,
      "step": 1760
    },
    {
      "epoch": 6.484848484848484,
      "grad_norm": 7.803122043609619,
      "learning_rate": 9.349632352941177e-05,
      "loss": 0.2015,
      "step": 1770
    },
    {
      "epoch": 6.521579430670339,
      "grad_norm": 10.115589141845703,
      "learning_rate": 9.345955882352942e-05,
      "loss": 0.2296,
      "step": 1780
    },
    {
      "epoch": 6.558310376492194,
      "grad_norm": 5.432443618774414,
      "learning_rate": 9.342279411764706e-05,
      "loss": 0.2179,
      "step": 1790
    },
    {
      "epoch": 6.595041322314049,
      "grad_norm": 7.170080661773682,
      "learning_rate": 9.338602941176471e-05,
      "loss": 0.2013,
      "step": 1800
    },
    {
      "epoch": 6.595041322314049,
      "eval_loss": 0.9534168839454651,
      "eval_runtime": 33.599,
      "eval_samples_per_second": 35.328,
      "eval_steps_per_second": 4.435,
      "step": 1800
    },
    {
      "epoch": 6.631772268135904,
      "grad_norm": 4.80239200592041,
      "learning_rate": 9.334926470588235e-05,
      "loss": 0.237,
      "step": 1810
    },
    {
      "epoch": 6.668503213957759,
      "grad_norm": 2.950042247772217,
      "learning_rate": 9.33125e-05,
      "loss": 0.2019,
      "step": 1820
    },
    {
      "epoch": 6.705234159779614,
      "grad_norm": 6.591917037963867,
      "learning_rate": 9.327573529411764e-05,
      "loss": 0.2121,
      "step": 1830
    },
    {
      "epoch": 6.741965105601469,
      "grad_norm": 4.248568534851074,
      "learning_rate": 9.32389705882353e-05,
      "loss": 0.1766,
      "step": 1840
    },
    {
      "epoch": 6.778696051423324,
      "grad_norm": 6.2198405265808105,
      "learning_rate": 9.320220588235295e-05,
      "loss": 0.1807,
      "step": 1850
    },
    {
      "epoch": 6.778696051423324,
      "eval_loss": 1.0146963596343994,
      "eval_runtime": 33.5751,
      "eval_samples_per_second": 35.354,
      "eval_steps_per_second": 4.438,
      "step": 1850
    },
    {
      "epoch": 6.815426997245179,
      "grad_norm": 5.191137313842773,
      "learning_rate": 9.316544117647059e-05,
      "loss": 0.2149,
      "step": 1860
    },
    {
      "epoch": 6.852157943067034,
      "grad_norm": 3.6549787521362305,
      "learning_rate": 9.312867647058824e-05,
      "loss": 0.2246,
      "step": 1870
    },
    {
      "epoch": 6.888888888888889,
      "grad_norm": 6.121376991271973,
      "learning_rate": 9.309191176470588e-05,
      "loss": 0.2171,
      "step": 1880
    },
    {
      "epoch": 6.925619834710744,
      "grad_norm": 7.67390251159668,
      "learning_rate": 9.305514705882353e-05,
      "loss": 0.2083,
      "step": 1890
    },
    {
      "epoch": 6.962350780532598,
      "grad_norm": 6.9193830490112305,
      "learning_rate": 9.301838235294117e-05,
      "loss": 0.2376,
      "step": 1900
    },
    {
      "epoch": 6.962350780532598,
      "eval_loss": 0.9892522692680359,
      "eval_runtime": 33.4753,
      "eval_samples_per_second": 35.459,
      "eval_steps_per_second": 4.451,
      "step": 1900
    },
    {
      "epoch": 6.999081726354453,
      "grad_norm": 5.750361442565918,
      "learning_rate": 9.298161764705883e-05,
      "loss": 0.257,
      "step": 1910
    },
    {
      "epoch": 7.033057851239669,
      "grad_norm": 5.609231948852539,
      "learning_rate": 9.294485294117648e-05,
      "loss": 0.1443,
      "step": 1920
    },
    {
      "epoch": 7.069788797061524,
      "grad_norm": 4.179663181304932,
      "learning_rate": 9.290808823529412e-05,
      "loss": 0.164,
      "step": 1930
    },
    {
      "epoch": 7.106519742883379,
      "grad_norm": 4.965925216674805,
      "learning_rate": 9.287132352941177e-05,
      "loss": 0.1692,
      "step": 1940
    },
    {
      "epoch": 7.143250688705234,
      "grad_norm": 3.3686349391937256,
      "learning_rate": 9.283455882352941e-05,
      "loss": 0.1756,
      "step": 1950
    },
    {
      "epoch": 7.143250688705234,
      "eval_loss": 1.0180176496505737,
      "eval_runtime": 33.5391,
      "eval_samples_per_second": 35.391,
      "eval_steps_per_second": 4.443,
      "step": 1950
    },
    {
      "epoch": 7.179981634527089,
      "grad_norm": 7.261910438537598,
      "learning_rate": 9.279779411764706e-05,
      "loss": 0.173,
      "step": 1960
    },
    {
      "epoch": 7.216712580348944,
      "grad_norm": 5.207125186920166,
      "learning_rate": 9.27610294117647e-05,
      "loss": 0.198,
      "step": 1970
    },
    {
      "epoch": 7.253443526170799,
      "grad_norm": 4.023634910583496,
      "learning_rate": 9.272426470588235e-05,
      "loss": 0.1652,
      "step": 1980
    },
    {
      "epoch": 7.290174471992654,
      "grad_norm": 4.2413225173950195,
      "learning_rate": 9.268750000000001e-05,
      "loss": 0.1626,
      "step": 1990
    },
    {
      "epoch": 7.326905417814508,
      "grad_norm": 3.025498390197754,
      "learning_rate": 9.265073529411766e-05,
      "loss": 0.1722,
      "step": 2000
    },
    {
      "epoch": 7.326905417814508,
      "eval_loss": 1.0654195547103882,
      "eval_runtime": 33.5557,
      "eval_samples_per_second": 35.374,
      "eval_steps_per_second": 4.44,
      "step": 2000
    },
    {
      "epoch": 7.363636363636363,
      "grad_norm": 3.80892014503479,
      "learning_rate": 9.26139705882353e-05,
      "loss": 0.1438,
      "step": 2010
    },
    {
      "epoch": 7.400367309458218,
      "grad_norm": 6.989057540893555,
      "learning_rate": 9.257720588235295e-05,
      "loss": 0.1878,
      "step": 2020
    },
    {
      "epoch": 7.437098255280073,
      "grad_norm": 7.405502796173096,
      "learning_rate": 9.254044117647059e-05,
      "loss": 0.1933,
      "step": 2030
    },
    {
      "epoch": 7.473829201101928,
      "grad_norm": 4.408109188079834,
      "learning_rate": 9.250367647058824e-05,
      "loss": 0.2084,
      "step": 2040
    },
    {
      "epoch": 7.510560146923783,
      "grad_norm": 5.931614398956299,
      "learning_rate": 9.246691176470588e-05,
      "loss": 0.1809,
      "step": 2050
    },
    {
      "epoch": 7.510560146923783,
      "eval_loss": 1.0481195449829102,
      "eval_runtime": 33.5881,
      "eval_samples_per_second": 35.34,
      "eval_steps_per_second": 4.436,
      "step": 2050
    },
    {
      "epoch": 7.547291092745638,
      "grad_norm": 4.65437126159668,
      "learning_rate": 9.243014705882354e-05,
      "loss": 0.1788,
      "step": 2060
    },
    {
      "epoch": 7.584022038567493,
      "grad_norm": 6.643553256988525,
      "learning_rate": 9.239338235294119e-05,
      "loss": 0.2249,
      "step": 2070
    },
    {
      "epoch": 7.620752984389348,
      "grad_norm": 6.132976055145264,
      "learning_rate": 9.235661764705883e-05,
      "loss": 0.1697,
      "step": 2080
    },
    {
      "epoch": 7.657483930211203,
      "grad_norm": 4.549838542938232,
      "learning_rate": 9.231985294117648e-05,
      "loss": 0.2109,
      "step": 2090
    },
    {
      "epoch": 7.694214876033058,
      "grad_norm": 3.0133912563323975,
      "learning_rate": 9.228308823529412e-05,
      "loss": 0.1737,
      "step": 2100
    },
    {
      "epoch": 7.694214876033058,
      "eval_loss": 1.002568244934082,
      "eval_runtime": 33.5144,
      "eval_samples_per_second": 35.418,
      "eval_steps_per_second": 4.446,
      "step": 2100
    },
    {
      "epoch": 7.730945821854913,
      "grad_norm": 2.9239134788513184,
      "learning_rate": 9.224632352941177e-05,
      "loss": 0.1935,
      "step": 2110
    },
    {
      "epoch": 7.767676767676767,
      "grad_norm": 6.073605060577393,
      "learning_rate": 9.220955882352941e-05,
      "loss": 0.2052,
      "step": 2120
    },
    {
      "epoch": 7.804407713498622,
      "grad_norm": 5.043976783752441,
      "learning_rate": 9.217279411764707e-05,
      "loss": 0.1409,
      "step": 2130
    },
    {
      "epoch": 7.841138659320477,
      "grad_norm": 5.669463157653809,
      "learning_rate": 9.213602941176472e-05,
      "loss": 0.1722,
      "step": 2140
    },
    {
      "epoch": 7.877869605142332,
      "grad_norm": 4.940777778625488,
      "learning_rate": 9.209926470588236e-05,
      "loss": 0.1939,
      "step": 2150
    },
    {
      "epoch": 7.877869605142332,
      "eval_loss": 1.0549951791763306,
      "eval_runtime": 33.3279,
      "eval_samples_per_second": 35.616,
      "eval_steps_per_second": 4.471,
      "step": 2150
    },
    {
      "epoch": 7.914600550964187,
      "grad_norm": 5.504940032958984,
      "learning_rate": 9.206250000000001e-05,
      "loss": 0.2234,
      "step": 2160
    },
    {
      "epoch": 7.951331496786042,
      "grad_norm": 4.318198204040527,
      "learning_rate": 9.202573529411765e-05,
      "loss": 0.2555,
      "step": 2170
    },
    {
      "epoch": 7.988062442607897,
      "grad_norm": 6.868165493011475,
      "learning_rate": 9.19889705882353e-05,
      "loss": 0.1945,
      "step": 2180
    },
    {
      "epoch": 8.022038567493112,
      "grad_norm": 8.162625312805176,
      "learning_rate": 9.195220588235294e-05,
      "loss": 0.2152,
      "step": 2190
    },
    {
      "epoch": 8.058769513314967,
      "grad_norm": 6.36738395690918,
      "learning_rate": 9.191544117647059e-05,
      "loss": 0.1727,
      "step": 2200
    },
    {
      "epoch": 8.058769513314967,
      "eval_loss": 1.04727303981781,
      "eval_runtime": 32.7079,
      "eval_samples_per_second": 36.291,
      "eval_steps_per_second": 4.555,
      "step": 2200
    },
    {
      "epoch": 8.095500459136822,
      "grad_norm": 5.061728000640869,
      "learning_rate": 9.187867647058825e-05,
      "loss": 0.138,
      "step": 2210
    },
    {
      "epoch": 8.132231404958677,
      "grad_norm": 5.348777770996094,
      "learning_rate": 9.18419117647059e-05,
      "loss": 0.1505,
      "step": 2220
    },
    {
      "epoch": 8.168962350780532,
      "grad_norm": 4.635469436645508,
      "learning_rate": 9.180514705882354e-05,
      "loss": 0.1456,
      "step": 2230
    },
    {
      "epoch": 8.205693296602387,
      "grad_norm": 6.040651798248291,
      "learning_rate": 9.176838235294118e-05,
      "loss": 0.1742,
      "step": 2240
    },
    {
      "epoch": 8.242424242424242,
      "grad_norm": 4.2110724449157715,
      "learning_rate": 9.173161764705883e-05,
      "loss": 0.1391,
      "step": 2250
    },
    {
      "epoch": 8.242424242424242,
      "eval_loss": 1.052476406097412,
      "eval_runtime": 32.6881,
      "eval_samples_per_second": 36.313,
      "eval_steps_per_second": 4.558,
      "step": 2250
    },
    {
      "epoch": 8.279155188246097,
      "grad_norm": 4.103095531463623,
      "learning_rate": 9.169485294117648e-05,
      "loss": 0.1521,
      "step": 2260
    },
    {
      "epoch": 8.315886134067952,
      "grad_norm": 4.64979362487793,
      "learning_rate": 9.165808823529412e-05,
      "loss": 0.1499,
      "step": 2270
    },
    {
      "epoch": 8.352617079889807,
      "grad_norm": 5.996148109436035,
      "learning_rate": 9.162132352941178e-05,
      "loss": 0.163,
      "step": 2280
    },
    {
      "epoch": 8.389348025711662,
      "grad_norm": 7.3160624504089355,
      "learning_rate": 9.158455882352943e-05,
      "loss": 0.1597,
      "step": 2290
    },
    {
      "epoch": 8.426078971533517,
      "grad_norm": 6.047531604766846,
      "learning_rate": 9.154779411764707e-05,
      "loss": 0.1499,
      "step": 2300
    },
    {
      "epoch": 8.426078971533517,
      "eval_loss": 1.067679524421692,
      "eval_runtime": 32.6074,
      "eval_samples_per_second": 36.403,
      "eval_steps_per_second": 4.57,
      "step": 2300
    },
    {
      "epoch": 8.462809917355372,
      "grad_norm": 4.319231986999512,
      "learning_rate": 9.151102941176472e-05,
      "loss": 0.1844,
      "step": 2310
    },
    {
      "epoch": 8.499540863177227,
      "grad_norm": 2.997960329055786,
      "learning_rate": 9.147426470588236e-05,
      "loss": 0.1265,
      "step": 2320
    },
    {
      "epoch": 8.536271808999082,
      "grad_norm": 5.038692474365234,
      "learning_rate": 9.14375e-05,
      "loss": 0.1885,
      "step": 2330
    },
    {
      "epoch": 8.573002754820937,
      "grad_norm": 4.9614667892456055,
      "learning_rate": 9.140073529411765e-05,
      "loss": 0.1502,
      "step": 2340
    },
    {
      "epoch": 8.609733700642792,
      "grad_norm": 4.767692565917969,
      "learning_rate": 9.13639705882353e-05,
      "loss": 0.1701,
      "step": 2350
    },
    {
      "epoch": 8.609733700642792,
      "eval_loss": 1.0387611389160156,
      "eval_runtime": 32.6151,
      "eval_samples_per_second": 36.394,
      "eval_steps_per_second": 4.568,
      "step": 2350
    },
    {
      "epoch": 8.646464646464647,
      "grad_norm": 5.107124328613281,
      "learning_rate": 9.132720588235296e-05,
      "loss": 0.1386,
      "step": 2360
    },
    {
      "epoch": 8.683195592286502,
      "grad_norm": 8.637490272521973,
      "learning_rate": 9.12904411764706e-05,
      "loss": 0.1651,
      "step": 2370
    },
    {
      "epoch": 8.719926538108357,
      "grad_norm": 4.987798690795898,
      "learning_rate": 9.125367647058825e-05,
      "loss": 0.1534,
      "step": 2380
    },
    {
      "epoch": 8.756657483930212,
      "grad_norm": 6.158514499664307,
      "learning_rate": 9.121691176470588e-05,
      "loss": 0.1635,
      "step": 2390
    },
    {
      "epoch": 8.793388429752067,
      "grad_norm": 4.059680461883545,
      "learning_rate": 9.118014705882352e-05,
      "loss": 0.1617,
      "step": 2400
    },
    {
      "epoch": 8.793388429752067,
      "eval_loss": 1.0831010341644287,
      "eval_runtime": 32.744,
      "eval_samples_per_second": 36.251,
      "eval_steps_per_second": 4.55,
      "step": 2400
    },
    {
      "epoch": 8.83011937557392,
      "grad_norm": 4.832426071166992,
      "learning_rate": 9.114338235294117e-05,
      "loss": 0.1887,
      "step": 2410
    },
    {
      "epoch": 8.866850321395775,
      "grad_norm": 4.705029010772705,
      "learning_rate": 9.110661764705883e-05,
      "loss": 0.146,
      "step": 2420
    },
    {
      "epoch": 8.90358126721763,
      "grad_norm": 3.6893362998962402,
      "learning_rate": 9.106985294117647e-05,
      "loss": 0.1738,
      "step": 2430
    },
    {
      "epoch": 8.940312213039485,
      "grad_norm": 3.158442258834839,
      "learning_rate": 9.103308823529412e-05,
      "loss": 0.1637,
      "step": 2440
    },
    {
      "epoch": 8.97704315886134,
      "grad_norm": 5.208881378173828,
      "learning_rate": 9.099632352941176e-05,
      "loss": 0.1522,
      "step": 2450
    },
    {
      "epoch": 8.97704315886134,
      "eval_loss": 1.0215535163879395,
      "eval_runtime": 32.6483,
      "eval_samples_per_second": 36.357,
      "eval_steps_per_second": 4.564,
      "step": 2450
    },
    {
      "epoch": 9.011019283746556,
      "grad_norm": 3.8358514308929443,
      "learning_rate": 9.095955882352941e-05,
      "loss": 0.2059,
      "step": 2460
    },
    {
      "epoch": 9.047750229568411,
      "grad_norm": 5.983382225036621,
      "learning_rate": 9.092279411764706e-05,
      "loss": 0.1547,
      "step": 2470
    },
    {
      "epoch": 9.084481175390266,
      "grad_norm": 2.1699187755584717,
      "learning_rate": 9.08860294117647e-05,
      "loss": 0.1354,
      "step": 2480
    },
    {
      "epoch": 9.121212121212121,
      "grad_norm": 6.556402206420898,
      "learning_rate": 9.084926470588236e-05,
      "loss": 0.1529,
      "step": 2490
    },
    {
      "epoch": 9.157943067033976,
      "grad_norm": 3.946178436279297,
      "learning_rate": 9.08125e-05,
      "loss": 0.1192,
      "step": 2500
    },
    {
      "epoch": 9.157943067033976,
      "eval_loss": 1.0781618356704712,
      "eval_runtime": 32.6425,
      "eval_samples_per_second": 36.364,
      "eval_steps_per_second": 4.565,
      "step": 2500
    },
    {
      "epoch": 9.194674012855831,
      "grad_norm": 3.3241703510284424,
      "learning_rate": 9.077573529411765e-05,
      "loss": 0.1238,
      "step": 2510
    },
    {
      "epoch": 9.231404958677686,
      "grad_norm": 8.189927101135254,
      "learning_rate": 9.07389705882353e-05,
      "loss": 0.1618,
      "step": 2520
    },
    {
      "epoch": 9.268135904499541,
      "grad_norm": 5.642652988433838,
      "learning_rate": 9.070220588235294e-05,
      "loss": 0.1478,
      "step": 2530
    },
    {
      "epoch": 9.304866850321396,
      "grad_norm": 3.404155969619751,
      "learning_rate": 9.066544117647059e-05,
      "loss": 0.1431,
      "step": 2540
    },
    {
      "epoch": 9.341597796143251,
      "grad_norm": 5.665318965911865,
      "learning_rate": 9.062867647058823e-05,
      "loss": 0.1524,
      "step": 2550
    },
    {
      "epoch": 9.341597796143251,
      "eval_loss": 1.0692524909973145,
      "eval_runtime": 32.6985,
      "eval_samples_per_second": 36.301,
      "eval_steps_per_second": 4.557,
      "step": 2550
    },
    {
      "epoch": 9.378328741965106,
      "grad_norm": 4.2146196365356445,
      "learning_rate": 9.059191176470588e-05,
      "loss": 0.1515,
      "step": 2560
    },
    {
      "epoch": 9.415059687786961,
      "grad_norm": 4.859257221221924,
      "learning_rate": 9.055514705882354e-05,
      "loss": 0.1361,
      "step": 2570
    },
    {
      "epoch": 9.451790633608816,
      "grad_norm": 3.8225388526916504,
      "learning_rate": 9.051838235294118e-05,
      "loss": 0.1248,
      "step": 2580
    },
    {
      "epoch": 9.488521579430671,
      "grad_norm": 4.465124130249023,
      "learning_rate": 9.048161764705883e-05,
      "loss": 0.1472,
      "step": 2590
    },
    {
      "epoch": 9.525252525252526,
      "grad_norm": 3.435248374938965,
      "learning_rate": 9.044485294117647e-05,
      "loss": 0.1589,
      "step": 2600
    },
    {
      "epoch": 9.525252525252526,
      "eval_loss": 1.0718122720718384,
      "eval_runtime": 32.6748,
      "eval_samples_per_second": 36.328,
      "eval_steps_per_second": 4.56,
      "step": 2600
    },
    {
      "epoch": 9.561983471074381,
      "grad_norm": 4.550436496734619,
      "learning_rate": 9.040808823529412e-05,
      "loss": 0.1293,
      "step": 2610
    },
    {
      "epoch": 9.598714416896236,
      "grad_norm": 2.322570323944092,
      "learning_rate": 9.037132352941176e-05,
      "loss": 0.1657,
      "step": 2620
    },
    {
      "epoch": 9.635445362718091,
      "grad_norm": 6.089666843414307,
      "learning_rate": 9.033455882352941e-05,
      "loss": 0.1748,
      "step": 2630
    },
    {
      "epoch": 9.672176308539944,
      "grad_norm": 4.928532123565674,
      "learning_rate": 9.029779411764707e-05,
      "loss": 0.1333,
      "step": 2640
    },
    {
      "epoch": 9.7089072543618,
      "grad_norm": 4.8843865394592285,
      "learning_rate": 9.026102941176471e-05,
      "loss": 0.1187,
      "step": 2650
    },
    {
      "epoch": 9.7089072543618,
      "eval_loss": 1.0791631937026978,
      "eval_runtime": 32.6197,
      "eval_samples_per_second": 36.389,
      "eval_steps_per_second": 4.568,
      "step": 2650
    },
    {
      "epoch": 9.745638200183654,
      "grad_norm": 6.799336910247803,
      "learning_rate": 9.022426470588236e-05,
      "loss": 0.167,
      "step": 2660
    },
    {
      "epoch": 9.782369146005509,
      "grad_norm": 3.874239444732666,
      "learning_rate": 9.01875e-05,
      "loss": 0.1413,
      "step": 2670
    },
    {
      "epoch": 9.819100091827364,
      "grad_norm": 4.473707675933838,
      "learning_rate": 9.015073529411765e-05,
      "loss": 0.1412,
      "step": 2680
    },
    {
      "epoch": 9.855831037649219,
      "grad_norm": 7.232719898223877,
      "learning_rate": 9.01139705882353e-05,
      "loss": 0.1555,
      "step": 2690
    },
    {
      "epoch": 9.892561983471074,
      "grad_norm": 4.517348766326904,
      "learning_rate": 9.007720588235294e-05,
      "loss": 0.1783,
      "step": 2700
    },
    {
      "epoch": 9.892561983471074,
      "eval_loss": 1.0271258354187012,
      "eval_runtime": 32.5769,
      "eval_samples_per_second": 36.437,
      "eval_steps_per_second": 4.574,
      "step": 2700
    },
    {
      "epoch": 9.929292929292929,
      "grad_norm": 3.8939077854156494,
      "learning_rate": 9.004044117647058e-05,
      "loss": 0.1355,
      "step": 2710
    },
    {
      "epoch": 9.966023875114784,
      "grad_norm": 3.990225315093994,
      "learning_rate": 9.000367647058824e-05,
      "loss": 0.1821,
      "step": 2720
    },
    {
      "epoch": 10.0,
      "grad_norm": 1.7953025102615356,
      "learning_rate": 8.996691176470589e-05,
      "loss": 0.154,
      "step": 2730
    },
    {
      "epoch": 10.036730945821855,
      "grad_norm": 5.255331993103027,
      "learning_rate": 8.993014705882353e-05,
      "loss": 0.1103,
      "step": 2740
    },
    {
      "epoch": 10.07346189164371,
      "grad_norm": 4.20947265625,
      "learning_rate": 8.989338235294118e-05,
      "loss": 0.1131,
      "step": 2750
    },
    {
      "epoch": 10.07346189164371,
      "eval_loss": 1.1200051307678223,
      "eval_runtime": 32.6314,
      "eval_samples_per_second": 36.376,
      "eval_steps_per_second": 4.566,
      "step": 2750
    },
    {
      "epoch": 10.110192837465565,
      "grad_norm": 2.7561492919921875,
      "learning_rate": 8.985661764705883e-05,
      "loss": 0.1274,
      "step": 2760
    },
    {
      "epoch": 10.14692378328742,
      "grad_norm": 4.272851943969727,
      "learning_rate": 8.981985294117647e-05,
      "loss": 0.1493,
      "step": 2770
    },
    {
      "epoch": 10.183654729109275,
      "grad_norm": 4.825275897979736,
      "learning_rate": 8.978308823529412e-05,
      "loss": 0.1183,
      "step": 2780
    },
    {
      "epoch": 10.22038567493113,
      "grad_norm": 3.291593074798584,
      "learning_rate": 8.974632352941177e-05,
      "loss": 0.1112,
      "step": 2790
    },
    {
      "epoch": 10.257116620752985,
      "grad_norm": 3.686368942260742,
      "learning_rate": 8.970955882352942e-05,
      "loss": 0.1069,
      "step": 2800
    },
    {
      "epoch": 10.257116620752985,
      "eval_loss": 1.1182245016098022,
      "eval_runtime": 32.6605,
      "eval_samples_per_second": 36.344,
      "eval_steps_per_second": 4.562,
      "step": 2800
    },
    {
      "epoch": 10.29384756657484,
      "grad_norm": 3.242901563644409,
      "learning_rate": 8.967279411764707e-05,
      "loss": 0.1006,
      "step": 2810
    },
    {
      "epoch": 10.330578512396695,
      "grad_norm": 3.0162413120269775,
      "learning_rate": 8.963602941176471e-05,
      "loss": 0.1091,
      "step": 2820
    },
    {
      "epoch": 10.36730945821855,
      "grad_norm": 5.1262125968933105,
      "learning_rate": 8.959926470588236e-05,
      "loss": 0.1115,
      "step": 2830
    },
    {
      "epoch": 10.404040404040405,
      "grad_norm": 4.468550205230713,
      "learning_rate": 8.95625e-05,
      "loss": 0.1445,
      "step": 2840
    },
    {
      "epoch": 10.44077134986226,
      "grad_norm": 3.844414234161377,
      "learning_rate": 8.952573529411765e-05,
      "loss": 0.1163,
      "step": 2850
    },
    {
      "epoch": 10.44077134986226,
      "eval_loss": 1.1588691473007202,
      "eval_runtime": 32.6741,
      "eval_samples_per_second": 36.328,
      "eval_steps_per_second": 4.56,
      "step": 2850
    },
    {
      "epoch": 10.477502295684113,
      "grad_norm": 2.1801419258117676,
      "learning_rate": 8.948897058823529e-05,
      "loss": 0.1224,
      "step": 2860
    },
    {
      "epoch": 10.514233241505968,
      "grad_norm": 5.692498683929443,
      "learning_rate": 8.945220588235295e-05,
      "loss": 0.1359,
      "step": 2870
    },
    {
      "epoch": 10.550964187327823,
      "grad_norm": 4.235518455505371,
      "learning_rate": 8.94154411764706e-05,
      "loss": 0.1194,
      "step": 2880
    },
    {
      "epoch": 10.587695133149678,
      "grad_norm": 6.905414581298828,
      "learning_rate": 8.937867647058824e-05,
      "loss": 0.15,
      "step": 2890
    },
    {
      "epoch": 10.624426078971533,
      "grad_norm": 4.418788909912109,
      "learning_rate": 8.934191176470589e-05,
      "loss": 0.1588,
      "step": 2900
    },
    {
      "epoch": 10.624426078971533,
      "eval_loss": 1.0582021474838257,
      "eval_runtime": 32.6874,
      "eval_samples_per_second": 36.314,
      "eval_steps_per_second": 4.558,
      "step": 2900
    },
    {
      "epoch": 10.661157024793388,
      "grad_norm": 6.964303016662598,
      "learning_rate": 8.930514705882353e-05,
      "loss": 0.1586,
      "step": 2910
    },
    {
      "epoch": 10.697887970615243,
      "grad_norm": 6.721076488494873,
      "learning_rate": 8.926838235294118e-05,
      "loss": 0.1465,
      "step": 2920
    },
    {
      "epoch": 10.734618916437098,
      "grad_norm": 6.08360481262207,
      "learning_rate": 8.923161764705882e-05,
      "loss": 0.1551,
      "step": 2930
    },
    {
      "epoch": 10.771349862258953,
      "grad_norm": 3.7428693771362305,
      "learning_rate": 8.919485294117648e-05,
      "loss": 0.1573,
      "step": 2940
    },
    {
      "epoch": 10.808080808080808,
      "grad_norm": 12.817805290222168,
      "learning_rate": 8.915808823529413e-05,
      "loss": 0.1124,
      "step": 2950
    },
    {
      "epoch": 10.808080808080808,
      "eval_loss": 1.1072756052017212,
      "eval_runtime": 32.645,
      "eval_samples_per_second": 36.361,
      "eval_steps_per_second": 4.564,
      "step": 2950
    },
    {
      "epoch": 10.844811753902663,
      "grad_norm": 5.396032810211182,
      "learning_rate": 8.912132352941177e-05,
      "loss": 0.171,
      "step": 2960
    },
    {
      "epoch": 10.881542699724518,
      "grad_norm": 6.032069206237793,
      "learning_rate": 8.908455882352942e-05,
      "loss": 0.1587,
      "step": 2970
    },
    {
      "epoch": 10.918273645546373,
      "grad_norm": 3.078960657119751,
      "learning_rate": 8.904779411764706e-05,
      "loss": 0.1164,
      "step": 2980
    },
    {
      "epoch": 10.955004591368228,
      "grad_norm": 3.015232563018799,
      "learning_rate": 8.901102941176471e-05,
      "loss": 0.1521,
      "step": 2990
    },
    {
      "epoch": 10.991735537190083,
      "grad_norm": 6.324245929718018,
      "learning_rate": 8.897426470588235e-05,
      "loss": 0.1446,
      "step": 3000
    },
    {
      "epoch": 10.991735537190083,
      "eval_loss": 1.0756566524505615,
      "eval_runtime": 32.5991,
      "eval_samples_per_second": 36.412,
      "eval_steps_per_second": 4.571,
      "step": 3000
    },
    {
      "epoch": 11.025711662075299,
      "grad_norm": 2.0446279048919678,
      "learning_rate": 8.89375e-05,
      "loss": 0.1039,
      "step": 3010
    },
    {
      "epoch": 11.062442607897154,
      "grad_norm": 6.931196689605713,
      "learning_rate": 8.890073529411766e-05,
      "loss": 0.1147,
      "step": 3020
    },
    {
      "epoch": 11.099173553719009,
      "grad_norm": 3.425097703933716,
      "learning_rate": 8.88639705882353e-05,
      "loss": 0.0831,
      "step": 3030
    },
    {
      "epoch": 11.135904499540864,
      "grad_norm": 3.7726778984069824,
      "learning_rate": 8.882720588235295e-05,
      "loss": 0.1186,
      "step": 3040
    },
    {
      "epoch": 11.172635445362719,
      "grad_norm": 5.705497741699219,
      "learning_rate": 8.87904411764706e-05,
      "loss": 0.1226,
      "step": 3050
    },
    {
      "epoch": 11.172635445362719,
      "eval_loss": 1.1074416637420654,
      "eval_runtime": 32.6688,
      "eval_samples_per_second": 36.334,
      "eval_steps_per_second": 4.561,
      "step": 3050
    },
    {
      "epoch": 11.209366391184574,
      "grad_norm": 2.4243791103363037,
      "learning_rate": 8.875367647058824e-05,
      "loss": 0.1069,
      "step": 3060
    },
    {
      "epoch": 11.246097337006429,
      "grad_norm": 5.859233856201172,
      "learning_rate": 8.871691176470589e-05,
      "loss": 0.1084,
      "step": 3070
    },
    {
      "epoch": 11.282828282828282,
      "grad_norm": 3.8774633407592773,
      "learning_rate": 8.868014705882353e-05,
      "loss": 0.1198,
      "step": 3080
    },
    {
      "epoch": 11.319559228650137,
      "grad_norm": 4.427309513092041,
      "learning_rate": 8.864338235294119e-05,
      "loss": 0.1291,
      "step": 3090
    },
    {
      "epoch": 11.356290174471992,
      "grad_norm": 5.073295593261719,
      "learning_rate": 8.860661764705884e-05,
      "loss": 0.1059,
      "step": 3100
    },
    {
      "epoch": 11.356290174471992,
      "eval_loss": 1.1183487176895142,
      "eval_runtime": 32.6641,
      "eval_samples_per_second": 36.34,
      "eval_steps_per_second": 4.562,
      "step": 3100
    },
    {
      "epoch": 11.393021120293847,
      "grad_norm": 4.051884651184082,
      "learning_rate": 8.856985294117648e-05,
      "loss": 0.1281,
      "step": 3110
    },
    {
      "epoch": 11.429752066115702,
      "grad_norm": 8.619285583496094,
      "learning_rate": 8.853308823529413e-05,
      "loss": 0.1295,
      "step": 3120
    },
    {
      "epoch": 11.466483011937557,
      "grad_norm": 8.044411659240723,
      "learning_rate": 8.849632352941177e-05,
      "loss": 0.1288,
      "step": 3130
    },
    {
      "epoch": 11.503213957759412,
      "grad_norm": 4.935775279998779,
      "learning_rate": 8.845955882352942e-05,
      "loss": 0.1137,
      "step": 3140
    },
    {
      "epoch": 11.539944903581267,
      "grad_norm": 3.1592416763305664,
      "learning_rate": 8.842279411764706e-05,
      "loss": 0.1143,
      "step": 3150
    },
    {
      "epoch": 11.539944903581267,
      "eval_loss": 1.1022982597351074,
      "eval_runtime": 32.6583,
      "eval_samples_per_second": 36.346,
      "eval_steps_per_second": 4.562,
      "step": 3150
    },
    {
      "epoch": 11.576675849403122,
      "grad_norm": 4.437254905700684,
      "learning_rate": 8.838602941176472e-05,
      "loss": 0.1276,
      "step": 3160
    },
    {
      "epoch": 11.613406795224977,
      "grad_norm": 4.893582820892334,
      "learning_rate": 8.834926470588237e-05,
      "loss": 0.1117,
      "step": 3170
    },
    {
      "epoch": 11.650137741046832,
      "grad_norm": 2.5690925121307373,
      "learning_rate": 8.831250000000001e-05,
      "loss": 0.1188,
      "step": 3180
    },
    {
      "epoch": 11.686868686868687,
      "grad_norm": 5.55595588684082,
      "learning_rate": 8.827573529411766e-05,
      "loss": 0.1552,
      "step": 3190
    },
    {
      "epoch": 11.723599632690542,
      "grad_norm": 9.476856231689453,
      "learning_rate": 8.82389705882353e-05,
      "loss": 0.1105,
      "step": 3200
    },
    {
      "epoch": 11.723599632690542,
      "eval_loss": 1.1120429039001465,
      "eval_runtime": 32.6192,
      "eval_samples_per_second": 36.39,
      "eval_steps_per_second": 4.568,
      "step": 3200
    },
    {
      "epoch": 11.760330578512397,
      "grad_norm": 8.397612571716309,
      "learning_rate": 8.820220588235295e-05,
      "loss": 0.1434,
      "step": 3210
    },
    {
      "epoch": 11.797061524334252,
      "grad_norm": 3.140726327896118,
      "learning_rate": 8.81654411764706e-05,
      "loss": 0.1293,
      "step": 3220
    },
    {
      "epoch": 11.833792470156107,
      "grad_norm": 5.165231227874756,
      "learning_rate": 8.812867647058824e-05,
      "loss": 0.1143,
      "step": 3230
    },
    {
      "epoch": 11.870523415977962,
      "grad_norm": 4.214475154876709,
      "learning_rate": 8.809191176470588e-05,
      "loss": 0.154,
      "step": 3240
    },
    {
      "epoch": 11.907254361799817,
      "grad_norm": 3.843857765197754,
      "learning_rate": 8.805514705882353e-05,
      "loss": 0.1289,
      "step": 3250
    },
    {
      "epoch": 11.907254361799817,
      "eval_loss": 1.0833381414413452,
      "eval_runtime": 32.7039,
      "eval_samples_per_second": 36.295,
      "eval_steps_per_second": 4.556,
      "step": 3250
    },
    {
      "epoch": 11.943985307621672,
      "grad_norm": 3.2895419597625732,
      "learning_rate": 8.801838235294118e-05,
      "loss": 0.1138,
      "step": 3260
    },
    {
      "epoch": 11.980716253443527,
      "grad_norm": 3.795274496078491,
      "learning_rate": 8.798161764705882e-05,
      "loss": 0.1471,
      "step": 3270
    },
    {
      "epoch": 12.014692378328743,
      "grad_norm": 3.765004873275757,
      "learning_rate": 8.794485294117647e-05,
      "loss": 0.1138,
      "step": 3280
    },
    {
      "epoch": 12.051423324150598,
      "grad_norm": 3.421272039413452,
      "learning_rate": 8.790808823529411e-05,
      "loss": 0.1132,
      "step": 3290
    },
    {
      "epoch": 12.088154269972453,
      "grad_norm": 3.726196050643921,
      "learning_rate": 8.787132352941177e-05,
      "loss": 0.0985,
      "step": 3300
    },
    {
      "epoch": 12.088154269972453,
      "eval_loss": 1.087640404701233,
      "eval_runtime": 32.6015,
      "eval_samples_per_second": 36.409,
      "eval_steps_per_second": 4.57,
      "step": 3300
    },
    {
      "epoch": 12.124885215794306,
      "grad_norm": 2.9305646419525146,
      "learning_rate": 8.783455882352942e-05,
      "loss": 0.1132,
      "step": 3310
    },
    {
      "epoch": 12.16161616161616,
      "grad_norm": 4.9123640060424805,
      "learning_rate": 8.779779411764706e-05,
      "loss": 0.1139,
      "step": 3320
    },
    {
      "epoch": 12.198347107438016,
      "grad_norm": 2.7400965690612793,
      "learning_rate": 8.77610294117647e-05,
      "loss": 0.0954,
      "step": 3330
    },
    {
      "epoch": 12.23507805325987,
      "grad_norm": 2.0259077548980713,
      "learning_rate": 8.772426470588235e-05,
      "loss": 0.1164,
      "step": 3340
    },
    {
      "epoch": 12.271808999081726,
      "grad_norm": 5.586324691772461,
      "learning_rate": 8.76875e-05,
      "loss": 0.1173,
      "step": 3350
    },
    {
      "epoch": 12.271808999081726,
      "eval_loss": 1.1255048513412476,
      "eval_runtime": 32.6067,
      "eval_samples_per_second": 36.404,
      "eval_steps_per_second": 4.57,
      "step": 3350
    },
    {
      "epoch": 12.30853994490358,
      "grad_norm": 3.6330068111419678,
      "learning_rate": 8.765073529411764e-05,
      "loss": 0.1303,
      "step": 3360
    },
    {
      "epoch": 12.345270890725436,
      "grad_norm": 2.5363988876342773,
      "learning_rate": 8.76139705882353e-05,
      "loss": 0.1044,
      "step": 3370
    },
    {
      "epoch": 12.38200183654729,
      "grad_norm": 8.600849151611328,
      "learning_rate": 8.757720588235295e-05,
      "loss": 0.0803,
      "step": 3380
    },
    {
      "epoch": 12.418732782369146,
      "grad_norm": 3.2504467964172363,
      "learning_rate": 8.754044117647059e-05,
      "loss": 0.0984,
      "step": 3390
    },
    {
      "epoch": 12.455463728191,
      "grad_norm": 3.1098134517669678,
      "learning_rate": 8.750367647058824e-05,
      "loss": 0.0996,
      "step": 3400
    },
    {
      "epoch": 12.455463728191,
      "eval_loss": 1.0940529108047485,
      "eval_runtime": 32.7227,
      "eval_samples_per_second": 36.275,
      "eval_steps_per_second": 4.553,
      "step": 3400
    },
    {
      "epoch": 12.492194674012856,
      "grad_norm": 3.8607406616210938,
      "learning_rate": 8.746691176470588e-05,
      "loss": 0.0793,
      "step": 3410
    },
    {
      "epoch": 12.52892561983471,
      "grad_norm": 3.370833158493042,
      "learning_rate": 8.743014705882353e-05,
      "loss": 0.1241,
      "step": 3420
    },
    {
      "epoch": 12.565656565656566,
      "grad_norm": 5.016992092132568,
      "learning_rate": 8.739338235294117e-05,
      "loss": 0.0989,
      "step": 3430
    },
    {
      "epoch": 12.60238751147842,
      "grad_norm": 3.8046445846557617,
      "learning_rate": 8.735661764705882e-05,
      "loss": 0.1395,
      "step": 3440
    },
    {
      "epoch": 12.639118457300276,
      "grad_norm": 3.317654848098755,
      "learning_rate": 8.731985294117648e-05,
      "loss": 0.1125,
      "step": 3450
    },
    {
      "epoch": 12.639118457300276,
      "eval_loss": 1.1126387119293213,
      "eval_runtime": 32.6097,
      "eval_samples_per_second": 36.4,
      "eval_steps_per_second": 4.569,
      "step": 3450
    }
  ],
  "logging_steps": 10,
  "max_steps": 27200,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 100,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.914134958473216e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
