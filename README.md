# few-shot Prompt KGC
Few-shot Prompt for Knowledge Graph Completion

> åœ¨å°‘æ ·æœ¬ï¼ˆK-shotï¼‰åœºæ™¯ä¸‹ï¼Œåˆ©ç”¨æç¤ºå·¥ç¨‹ï¼ˆPromptingï¼‰ä¸å¯é€‰çš„æ£€ç´¢å¢å¼ºï¼Œå¯¹çŸ¥è¯†å›¾è°±è¿›è¡Œç¼ºå¤±ä¸‰å…ƒç»„è¡¥å…¨ä¸æ¨ç†ã€‚

**Last updated:** 2025-08-12

## âœ¨ Highlights
- **Few-shot æç¤º**ï¼šç”¨æå°‘ç¤ºä¾‹é©±åŠ¨å…³ç³»/å®ä½“æ¨æ–­ã€‚
- **å¯é€‰ Graph-RAG æ£€ç´¢å¢å¼º**ï¼šä»å›¾æˆ–æ–‡æœ¬ä¾§æ£€ç´¢è¯æ®ï¼Œæ‹¼æ¥åˆ°æç¤ºä¸­ã€‚
- **å¯¹æ¯”ä¼ ç»Ÿ KGE**ï¼šä¸ `torchKGE/` ä¸‹åµŒå…¥å¼æ–¹æ³•åšæŒ‡æ ‡å¯¹ç…§ã€‚
- **Notebook ä¸Šæ‰‹**ï¼šæä¾›â€œæ•°æ®æŠ½æ · / æ¨¡å‹æµ‹è¯• / æµ‹è¯•ä»£ç â€3 ä¸ªç¤ºä¾‹ç¬”è®°æœ¬ã€‚

## ğŸ“¦ Repository Structure
```text
few-shot-Prompt-KGC/
â”œâ”€ graphRAG/                    # æ£€ç´¢ä¸ä¸Šä¸‹æ–‡æ•´ç†ï¼ˆGraph-RAG é£æ ¼ï¼Œå¯é€‰ï¼‰
â”œâ”€ knowledge_graph_completion/  # Few-shot ä»»åŠ¡/æç¤ºç›¸å…³ä»£ç 
â”œâ”€ torchKGE/                    # ä¼ ç»ŸåµŒå…¥å¼ KGE åŸºçº¿
â”œâ”€ outputs/                     # ç»“æœä¸å¯è§†åŒ–è¾“å‡º
â”œâ”€ æ•°æ®æŠ½æ ·.ipynb
â”œâ”€ æ¨¡å‹æµ‹è¯•.ipynb
â””â”€ æµ‹è¯•ä»£ç .ipynb
````

> ä»¥ä¸Šç»“æ„ä¾æ®ä»“åº“å½“å‰å¯è§å†…å®¹ï¼Œå¦‚æœ‰æ–°å¢/é‡å‘½åä»¥å®é™…ä¸ºå‡†ã€‚
> Source: repo root file list. ([GitHub][1])

## ğŸ›  Environment

* Python 3.9+ï¼ˆå»ºè®® 3.10ï¼‰
* è§ `requirements.txt`ï¼ˆå¯æŒ‰éœ€åˆ å‡ï¼‰
* å¯ä½¿ç”¨ GPUï¼ˆPyTorch CUDAï¼‰

Quick start:

```bash
conda create -n promptkgc python=3.10 -y
conda activate promptkgc
pip install -r requirements.txt
```

## âš™ï¸ Configuration

åœ¨é¡¹ç›®æ ¹ç›®å½•æ–°å»º/ä¿®æ”¹ `config.yaml`ï¼ˆç¤ºä¾‹ï¼‰ï¼š

```yaml
seed: 42
device: "cuda:0"     # æˆ– "cpu"

task: "tail-prediction"   # æ”¯æŒ: tail-prediction / head-prediction / relation-prediction
k_shots: 5
candidate_pool_size: 100  # é—­é›†å€™é€‰ä¸Šé™

data:
  root: "./data"
  dataset: "your_dataset"  # ä½ çš„æ•°æ®é›†ç›®å½•å
  fewshot_dir: "./data/your_dataset/fewshot"

retrieval:
  enable: true
  topk: 8
  encoder: "sentence-transformers/all-MiniLM-L6-v2"
  index: "faiss"

llm:
  provider: "openai"      # æˆ– "dashscope"/"azure"/"qianfan" ç­‰
  model: "gpt-4o"         # æ›¿æ¢ä¸ºä½ çœŸå®ä½¿ç”¨çš„æ¨¡å‹
  temperature: 0.0
  max_tokens: 512
  api_key: "${OPENAI_API_KEY}"   # ä»ç¯å¢ƒå˜é‡è¯»å–

prompt:
  template: "./knowledge_graph_completion/prompts/fewshot_tail.txt"
  place_examples: "before_query"  # few-shot ç¤ºä¾‹æ”¾ç½®ç­–ç•¥

paths:
  out_dir: "./outputs"
```

## ğŸ“š Data Layout

å°†æ•°æ®æ”¾åœ¨ `./data/{your_dataset}/`ï¼š

```
data/
  your_dataset/
    train.txt       # æ¯è¡Œ: head \t relation \t tail
    valid.txt
    test.txt
    entities.txt
    relations.txt
```

ç”¨ `æ•°æ®æŠ½æ ·.ipynb` ç”Ÿæˆ few-shot åˆ‡åˆ†ï¼ˆæ”¯æŒé›†/æŸ¥è¯¢é›†ï¼‰ï¼Œè¾“å‡ºåˆ° `data/your_dataset/fewshot/`ï¼Œä¾› few-shot æç¤ºæ¨ç†ä¸è¯„æµ‹ä½¿ç”¨ã€‚([GitHub][1])

## ğŸš€ How to Run

### æ–¹å¼ Aï¼šNotebookï¼ˆæ¨èå¿«é€Ÿä¸Šæ‰‹ï¼‰

1. æ‰“å¼€ `æ•°æ®æŠ½æ ·.ipynb`ï¼šæŒ‰å…³ç³»é‡‡æ · K-shot æ”¯æŒé›†ä¸æŸ¥è¯¢é›†ï¼›
2. æ‰“å¼€ `æ¨¡å‹æµ‹è¯•.ipynb`ï¼šé…ç½® `config.yaml` è·¯å¾„ï¼Œè¿è¡Œ few-shot æ¨ç†ä¸æŒ‡æ ‡ç»Ÿè®¡ï¼›
3. æ‰“å¼€ `æµ‹è¯•ä»£ç .ipynb`ï¼šç”¨äºä»£ç ç‰‡æ®µéªŒè¯ä¸å¯è§†åŒ–ã€‚

> è¿è¡Œååœ¨ `outputs/` ä¸‹ç”Ÿæˆæ—¥å¿—ã€å›¾è¡¨ä¸è¯„æµ‹ CSVã€‚([GitHub][1])

### æ–¹å¼ Bï¼šPython è„šæœ¬ï¼ˆå¦‚æœä½ å·²æä¾›å…¥å£ï¼‰

> è‹¥ä½ åç»­æ·»åŠ äº†å‘½ä»¤è¡Œè„šæœ¬ï¼Œå¯å‚è€ƒå¦‚ä¸‹çº¦å®šå‘½ä»¤ï¼ˆç¤ºä¾‹ï¼‰ï¼š

```bash
# Few-shot + æ£€ç´¢å¢å¼º
python -m knowledge_graph_completion.run \
  --config config.yaml \
  --task tail-prediction \
  --use-retrieval \
  --out ./outputs/run_$(date +%F)

# ä¼ ç»Ÿ KGE åŸºçº¿
python -m torchKGE.train \
  --data ./data/your_dataset \
  --model transe --dim 400 --epochs 100 \
  --out ./outputs/transe_baseline
```

## ğŸ“ˆ Metrics

* **MRR**ï¼ˆMean Reciprocal Rankï¼‰
* **Hits\@k**ï¼ˆk âˆˆ {1,3,10}ï¼‰
* å¯é€‰ï¼šAccuracyï¼ˆé—­é›†å€™é€‰æ—¶ï¼‰

å»ºè®®ï¼šè¾“å‡ºæ€»ä½“ + æŒ‰å…³ç³»é¢‘æ¬¡åˆ†æ¡¶ï¼ˆé•¿å°¾å¯¹æ¯”ï¼‰+ æ¡ˆä¾‹å¯è§†åŒ–ï¼ˆå«æç¤ºä¸æ£€ç´¢è¯æ®ï¼‰ã€‚

## ğŸ” Reproducibility Checklist

* å›ºå®š `seed / k_shots / candidate_pool_size / è¯„æµ‹åè®®ï¼ˆæ˜¯å¦è¿‡æ»¤å·²çŸ¥ä¸‰å…ƒç»„ï¼‰`
* å…¬å¸ƒ LLM åç§°/ç‰ˆæœ¬ã€`temperature / max_tokens`
* è´´å‡ºå®Œæ•´æç¤ºæ¨¡æ¿ä¸ç¤ºä¾‹é‡‡æ ·ç­–ç•¥
* æ ‡æ³¨æ£€ç´¢ encoder/index å…·ä½“ç‰ˆæœ¬ä¸å‚æ•°
* ç‰ˆæœ¬åŒ– `outputs/` ä¸ `config.yaml`

## ğŸ¤ Contributing

æ¬¢è¿ PR / Issueï¼š

* æ–°çš„æ•°æ®å¤„ç†è„šæœ¬ä¸è¯„æµ‹åè®®
* æ›´å¤šæç¤ºæ¨¡æ¿ä¸é‡‡æ ·ç­–ç•¥
* æ–°çš„æ£€ç´¢å™¨ã€æ¶ˆæ­§ä¸è¯æ®è·¯ç”±æ–¹æ³•
* KGE/LLM æ··åˆæ¨ç†æ”¹è¿›

## ğŸ“„ License

æœ¬ä»“åº“å¦‚æœªé™„å¸¦ LICENSE æ–‡ä»¶ï¼Œé»˜è®¤ä¿ç•™æ‰€æœ‰æƒåˆ©ï¼›å»ºè®®æ·»åŠ  `MIT` æˆ– `Apache-2.0` è®¸å¯è¯ï¼Œä¾¿äºåä½œä¸å¤ç°ã€‚

## ğŸ™ Acknowledgements

æ„Ÿè°¢ç¤¾åŒºåœ¨å°‘æ ·æœ¬ KGCã€æç¤ºå­¦ä¹ ä¸å›¾æ£€ç´¢æ–¹å‘çš„å…¬å¼€å·¥ä½œä¸å¯å‘ã€‚

````

---

### requirements.txt

```txt
# Core
numpy>=1.24
pandas>=2.0
scipy>=1.11
scikit-learn>=1.3
tqdm>=4.66

# Deep learning
torch>=2.1
torchvision>=0.16
torchaudio>=2.1

# LLM / prompts (ä»»é€‰å…¶ä¸€æˆ–å¤šå®¶ï¼Œæ ¹æ®ä½ å®é™…è°ƒç”¨æ”¹åŠ¨)
openai>=1.30
httpx>=0.27
transformers>=4.42

# Retrieval / text encoders (å¦‚å¯ç”¨ Graph-RAG/å‘é‡ç´¢å¼•)
sentence-transformers>=2.5
faiss-cpu>=1.7.4
networkx>=3.2

# Utils
pyyaml>=6.0.1
matplotlib>=3.8
ipykernel>=6.29
jupyter>=1.0
````

> å¦‚æœä½ çš„ `torchKGE/` æˆ– `knowledge_graph_completion/` å†…å·²å›ºå®šæŸäº›åº“ç‰ˆæœ¬ï¼Œè¯·æŠŠä¸Šè¿°ç‰ˆæœ¬å·æ”¹æˆä¸ä½ ä»£ç ä¸€è‡´çš„èŒƒå›´ã€‚

---

### config.yamlï¼ˆç¤ºä¾‹ï¼‰

```yaml
seed: 42
device: "cuda:0"     # æˆ– "cpu"

task: "tail-prediction"   # tail-prediction / head-prediction / relation-prediction
k_shots: 5
candidate_pool_size: 100

data:
  root: "./data"
  dataset: "your_dataset"
  fewshot_dir: "./data/your_dataset/fewshot"

retrieval:
  enable: true
  topk: 8
  encoder: "sentence-transformers/all-MiniLM-L6-v2"
  index: "faiss"

llm:
  provider: "openai"
  model: "gpt-4o"
  temperature: 0.0
  max_tokens: 512
  api_key: "${OPENAI_API_KEY}"   # å»ºè®®ç”¨ç¯å¢ƒå˜é‡æ³¨å…¥

prompt:
  template: "./knowledge_graph_completion/prompts/fewshot_tail.txt"
  place_examples: "before_query"

paths:
  out_dir: "./outputs"
```
